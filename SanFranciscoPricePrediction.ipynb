{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "earned-joyce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/tensorflow/python/framework/dtypes.py:463: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/tensorflow/python/framework/dtypes.py:464: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/tensorflow/python/framework/dtypes.py:465: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/tensorflow/python/framework/dtypes.py:466: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/tensorflow/python/framework/dtypes.py:467: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score\n",
    "from keras import models, layers, optimizers, regularizers\n",
    "from sklearn.ensemble import RandomForestRegressor, ExtraTreesRegressor, GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "studied-preparation",
   "metadata": {},
   "source": [
    "### From our work on the seattle data, we've determined what the best columns are. We'll keep those for this dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "external-robin",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['id', 'listing_url', 'scrape_id', 'last_scraped', 'name', 'summary',\n",
      "       'space', 'description', 'experiences_offered', 'neighborhood_overview',\n",
      "       ...\n",
      "       'instant_bookable', 'is_business_travel_ready', 'cancellation_policy',\n",
      "       'require_guest_profile_picture', 'require_guest_phone_verification',\n",
      "       'calculated_host_listings_count',\n",
      "       'calculated_host_listings_count_entire_homes',\n",
      "       'calculated_host_listings_count_private_rooms',\n",
      "       'calculated_host_listings_count_shared_rooms', 'reviews_per_month'],\n",
      "      dtype='object', length=106)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('san_francisco_listings.csv')\n",
    "df = df.rename(columns={'neighbourhood_cleansed':'neighbourhood_group'})\n",
    "print(df.columns)\n",
    "cols_to_keep = ['host_response_time', 'host_response_rate', 'host_has_profile_pic',\n",
    "       'neighbourhood_group', 'zipcode', 'market', 'smart_location',\n",
    "       'latitude', 'longitude', 'is_location_exact', 'property_type',\n",
    "       'room_type', 'accommodates', 'bathrooms', 'bedrooms', 'beds', 'bed_type', 'price',\n",
    "       'guests_included', 'extra_people', 'minimum_nights', 'maximum_nights', 'calendar_updated',\n",
    "       'has_availability', 'availability_90', 'number_of_reviews', 'first_review', 'last_review',\n",
    "       'requires_license', 'instant_bookable', 'cancellation_policy',\n",
    "       'require_guest_profile_picture', 'require_guest_phone_verification', 'security_deposit', 'cleaning_fee']\n",
    "\n",
    "\n",
    "df = df[cols_to_keep]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "considered-captain",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "descending-fleet",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "host_response_time                   927\n",
      "host_response_rate                   927\n",
      "host_has_profile_pic                   8\n",
      "neighbourhood_group                    0\n",
      "zipcode                              245\n",
      "market                                21\n",
      "smart_location                         0\n",
      "latitude                               0\n",
      "longitude                              0\n",
      "is_location_exact                      0\n",
      "property_type                          0\n",
      "room_type                              0\n",
      "accommodates                           0\n",
      "bathrooms                             12\n",
      "bedrooms                               4\n",
      "beds                                   9\n",
      "bed_type                               0\n",
      "price                                  0\n",
      "guests_included                        0\n",
      "extra_people                           0\n",
      "minimum_nights                         0\n",
      "maximum_nights                         0\n",
      "calendar_updated                       0\n",
      "has_availability                       0\n",
      "availability_90                        0\n",
      "number_of_reviews                      0\n",
      "first_review                        1605\n",
      "last_review                         1605\n",
      "requires_license                       0\n",
      "instant_bookable                       0\n",
      "cancellation_policy                    0\n",
      "require_guest_profile_picture          0\n",
      "require_guest_phone_verification       0\n",
      "security_deposit                    1692\n",
      "cleaning_fee                         924\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "royal-leadership",
   "metadata": {},
   "outputs": [],
   "source": [
    "useless = ['host_response_time', 'host_response_rate', 'zipcode', \n",
    "           'first_review', 'last_review', 'cleaning_fee']\n",
    "df = df.drop(useless, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "theoretical-foundation",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['host_has_profile_pic', 'neighbourhood_group', 'market',\n",
       "       'smart_location', 'latitude', 'longitude', 'is_location_exact',\n",
       "       'property_type', 'room_type', 'accommodates', 'bathrooms', 'bedrooms',\n",
       "       'beds', 'bed_type', 'price', 'guests_included', 'extra_people',\n",
       "       'minimum_nights', 'maximum_nights', 'calendar_updated',\n",
       "       'has_availability', 'availability_90', 'number_of_reviews',\n",
       "       'requires_license', 'instant_bookable', 'cancellation_policy',\n",
       "       'require_guest_profile_picture', 'require_guest_phone_verification',\n",
       "       'security_deposit'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "competent-identifier",
   "metadata": {},
   "source": [
    "### Now, we'll perform the same feature engineering and test the same neural networks to confirm neural nets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "digital-greeting",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-0b656e988400>:6: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will*not* be treated as literal strings when regex=True.\n",
      "  df.price = df.price.str.replace(\".\", \"\") # decimal at end\n",
      "<ipython-input-11-0b656e988400>:11: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will*not* be treated as literal strings when regex=True.\n",
      "  df.extra_people = df.extra_people.str.replace(\".\", \"\")\n"
     ]
    }
   ],
   "source": [
    "for col in ['bathrooms', 'bedrooms', 'beds']:\n",
    "    df[col].fillna(df[col].mean(), inplace=True)\n",
    "\n",
    "df.price = df.price.str[1:-3]\n",
    "df.price = df.price.str.replace(\",\", \"\")\n",
    "df.price = df.price.str.replace(\".\", \"\") # decimal at end\n",
    "df.price = df.price.astype('int64')\n",
    "\n",
    "df.extra_people = df.extra_people.str[1:-3]\n",
    "df.extra_people = df.extra_people.str.replace(\",\", \"\")\n",
    "df.extra_people = df.extra_people.str.replace(\".\", \"\")\n",
    "df.extra_people = df.extra_people.astype('int64')\n",
    "\n",
    "# df.cleaning_fee = df.cleaning_fee.str[1:-3]\n",
    "# df.cleaning_fee = df.cleaning_fee.str.replace(\",\", \"\")\n",
    "# df.cleaning_fee = df.cleaning_fee.str.replace(\".\", \"\")\n",
    "# df.cleaning_fee = df.cleaning_fee.astype('float64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "systematic-perth",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for col in ['bathrooms', 'bedrooms', 'beds']:\n",
    "#     df[col].fillna(df[col].mean(), inplace=True)\n",
    "    \n",
    "# df.price = df.price.str[1:-3]\n",
    "# df.price = df.price.str.replace(\",\", \"\")\n",
    "# df.price = df.price.str.replace(\".\", \"\") # decimal at end\n",
    "# df.price = df.price.astype('int64')\n",
    "\n",
    "# df.extra_people = df.extra_people.str[1:-3]\n",
    "# df.extra_people = df.extra_people.str.replace(\",\", \"\")\n",
    "# df.extra_people = df.extra_people.str.replace(\".\", \"\")\n",
    "# df.extra_people = df.extra_people.astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ideal-belarus",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['property_type'] = df.property_type.replace({\n",
    "    'Townhouse': 'House',\n",
    "    'Bungalow': 'House',\n",
    "    'Loft': 'Apartment',\n",
    "    'Chalet': 'Cabin',\n",
    "    'Tiny house': 'House',\n",
    "    'Earth house': 'House',\n",
    "    'Condominium': 'Apartment',\n",
    "    'Boutique hotel': 'Hotel',\n",
    "    'Aparthotel': 'Hotel',\n",
    "    'Serviced apartment': 'Apartment'\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "impaired-julian",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "spoken-banana",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_df = pd.get_dummies(df)\n",
    "\n",
    "# to_drop = ['beds',\n",
    "#            'bedrooms',\n",
    "#            'guests_included',\n",
    "#            'room_type_Private room']\n",
    "# to_drop.extend(list(transformed_df.columns[transformed_df.columns.str.endswith('nan')]))\n",
    "# transformed_df = transformed_df.drop(to_drop, axis=1, inplace=False)\n",
    "\n",
    "numerical_columns = ['accommodates', 'availability_90', 'bathrooms', 'extra_people',\n",
    "                     'maximum_nights', 'minimum_nights', 'number_of_reviews',\n",
    "                     'price']\n",
    "\n",
    "numerical_columns = [i for i in numerical_columns if i not in ['availability_90']]# Removing items not to be transformed\n",
    "\n",
    "for col in numerical_columns:\n",
    "    transformed_df[col] = transformed_df[col].astype('float64').replace(0.0, 0.01) # Replacing 0s with 0.01 because log(0) undefined\n",
    "    transformed_df[col] = np.log(transformed_df[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "helpful-folks",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['latitude', 'longitude', 'accommodates', 'bathrooms', 'bedrooms',\n",
      "       'beds', 'guests_included', 'extra_people', 'minimum_nights',\n",
      "       'maximum_nights',\n",
      "       ...\n",
      "       'security_deposit_$850.00 ', 'security_deposit_$899.00 ',\n",
      "       'security_deposit_$900.00 ', 'security_deposit_$95.00 ',\n",
      "       'security_deposit_$950.00 ', 'security_deposit_$960.00 ',\n",
      "       'security_deposit_$975.00 ', 'security_deposit_$990.00 ',\n",
      "       'security_deposit_$995.00 ', 'security_deposit_$999.00 '],\n",
      "      dtype='object', length=266)\n"
     ]
    }
   ],
   "source": [
    "X = transformed_df.drop('price', axis=1)\n",
    "y = transformed_df.price\n",
    "\n",
    "scaler = StandardScaler()\n",
    "print(X.columns)\n",
    "X = pd.DataFrame(scaler.fit_transform(X), columns=list(X.columns))\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "needed-drilling",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nn_model_evaluation(model, skip_epochs=0, X_train=X_train, X_test=X_test, y_train=y_train, y_test=y_test):\n",
    "    y_test_pred = model.predict(X_test)\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    print(\"Training MSE:\", round(mean_squared_error(y_train, y_train_pred),4))\n",
    "    print(\"Validation MSE:\", round(mean_squared_error(y_test, y_test_pred),4))\n",
    "    print(\"\\nTraining r2:\", round(r2_score(y_train, y_train_pred),4))\n",
    "    print(\"Validation r2:\", round(r2_score(y_test, y_test_pred),4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "political-patrick",
   "metadata": {},
   "source": [
    "### Now, we can test the same neural networks to see what happens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dangerous-priority",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "R^2 Train: 0.958037509857866\n",
      "R^2 Test: 0.7191792936689214\n",
      "\n",
      "R^2 Train: 0.9382484553733835\n",
      "R^2 Test: 0.725731831965202\n",
      "\n",
      "R^2 Train: 0.8061763128584237\n",
      "R^2 Test: 0.7137513726471116\n"
     ]
    }
   ],
   "source": [
    "def ModelResults(classifier):\n",
    "    classifier.fit(X_train, y_train)\n",
    "    train_predict = classifier.predict(X_train)\n",
    "    test_predict = classifier.predict(X_test)\n",
    "    print(\"\\nR^2 Train:\", r2_score(y_train, train_predict))\n",
    "    print(\"R^2 Test:\", r2_score(y_test, test_predict))\n",
    "    \n",
    "ETR = ExtraTreesRegressor(max_depth=17, n_estimators=100, n_jobs=-1)\n",
    "RFR = RandomForestRegressor(max_depth=17, n_estimators=100, n_jobs=-1)\n",
    "GBR = GradientBoostingRegressor(n_estimators=200, learning_rate=0.2)\n",
    "ModelResults(ETR)\n",
    "ModelResults(RFR)\n",
    "ModelResults(GBR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "settled-upgrade",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5839 samples, validate on 649 samples\n",
      "Epoch 1/200\n",
      "5839/5839 [==============================] - 1s 146us/step - loss: 137.9855 - mean_squared_error: 6.0543 - val_loss: 131.9889 - val_mean_squared_error: 3.2000\n",
      "Epoch 2/200\n",
      "5839/5839 [==============================] - 1s 86us/step - loss: 127.2457 - mean_squared_error: 1.2175 - val_loss: 124.0643 - val_mean_squared_error: 1.0970\n",
      "Epoch 3/200\n",
      "5839/5839 [==============================] - 1s 87us/step - loss: 120.8148 - mean_squared_error: 0.5618 - val_loss: 118.0452 - val_mean_squared_error: 0.7816\n",
      "Epoch 4/200\n",
      "5839/5839 [==============================] - 0s 83us/step - loss: 114.9913 - mean_squared_error: 0.3757 - val_loss: 112.3748 - val_mean_squared_error: 0.6704\n",
      "Epoch 5/200\n",
      "5839/5839 [==============================] - 0s 85us/step - loss: 109.4552 - mean_squared_error: 0.3308 - val_loss: 106.8600 - val_mean_squared_error: 0.5719\n",
      "Epoch 6/200\n",
      "5839/5839 [==============================] - 0s 82us/step - loss: 104.0580 - mean_squared_error: 0.2839 - val_loss: 101.5391 - val_mean_squared_error: 0.5282\n",
      "Epoch 7/200\n",
      "5839/5839 [==============================] - 1s 88us/step - loss: 98.8249 - mean_squared_error: 0.2607 - val_loss: 96.3633 - val_mean_squared_error: 0.4877\n",
      "Epoch 8/200\n",
      "5839/5839 [==============================] - 1s 89us/step - loss: 93.7456 - mean_squared_error: 0.2504 - val_loss: 91.3337 - val_mean_squared_error: 0.4539\n",
      "Epoch 9/200\n",
      "5839/5839 [==============================] - 1s 100us/step - loss: 88.8074 - mean_squared_error: 0.2402 - val_loss: 86.4554 - val_mean_squared_error: 0.4283\n",
      "Epoch 10/200\n",
      "5839/5839 [==============================] - 0s 84us/step - loss: 84.0141 - mean_squared_error: 0.2331 - val_loss: 81.7217 - val_mean_squared_error: 0.4066\n",
      "Epoch 11/200\n",
      "5839/5839 [==============================] - 0s 83us/step - loss: 79.3641 - mean_squared_error: 0.2280 - val_loss: 77.1354 - val_mean_squared_error: 0.3913\n",
      "Epoch 12/200\n",
      "5839/5839 [==============================] - 0s 84us/step - loss: 74.8560 - mean_squared_error: 0.2250 - val_loss: 72.6858 - val_mean_squared_error: 0.3736\n",
      "Epoch 13/200\n",
      "5839/5839 [==============================] - 1s 100us/step - loss: 70.4867 - mean_squared_error: 0.2219 - val_loss: 68.3808 - val_mean_squared_error: 0.3604\n",
      "Epoch 14/200\n",
      "5839/5839 [==============================] - 1s 87us/step - loss: 66.2583 - mean_squared_error: 0.2209 - val_loss: 64.2115 - val_mean_squared_error: 0.3478\n",
      "Epoch 15/200\n",
      "5839/5839 [==============================] - 1s 89us/step - loss: 62.1671 - mean_squared_error: 0.2182 - val_loss: 60.1897 - val_mean_squared_error: 0.3396\n",
      "Epoch 16/200\n",
      "5839/5839 [==============================] - 1s 87us/step - loss: 58.2201 - mean_squared_error: 0.2177 - val_loss: 56.3091 - val_mean_squared_error: 0.3315\n",
      "Epoch 17/200\n",
      "5839/5839 [==============================] - 1s 95us/step - loss: 54.4146 - mean_squared_error: 0.2194 - val_loss: 52.5680 - val_mean_squared_error: 0.3249\n",
      "Epoch 18/200\n",
      "5839/5839 [==============================] - 0s 83us/step - loss: 50.7446 - mean_squared_error: 0.2182 - val_loss: 48.9682 - val_mean_squared_error: 0.3176\n",
      "Epoch 19/200\n",
      "5839/5839 [==============================] - 0s 85us/step - loss: 47.2175 - mean_squared_error: 0.2187 - val_loss: 45.5068 - val_mean_squared_error: 0.3122\n",
      "Epoch 20/200\n",
      "5839/5839 [==============================] - 1s 87us/step - loss: 43.8308 - mean_squared_error: 0.2204 - val_loss: 42.1885 - val_mean_squared_error: 0.3099\n",
      "Epoch 21/200\n",
      "5839/5839 [==============================] - 1s 90us/step - loss: 40.5841 - mean_squared_error: 0.2217 - val_loss: 39.0105 - val_mean_squared_error: 0.3058\n",
      "Epoch 22/200\n",
      "5839/5839 [==============================] - 1s 88us/step - loss: 37.4769 - mean_squared_error: 0.2235 - val_loss: 35.9724 - val_mean_squared_error: 0.3011\n",
      "Epoch 23/200\n",
      "5839/5839 [==============================] - 0s 85us/step - loss: 34.5097 - mean_squared_error: 0.2258 - val_loss: 33.0756 - val_mean_squared_error: 0.3044\n",
      "Epoch 24/200\n",
      "5839/5839 [==============================] - 1s 87us/step - loss: 31.6809 - mean_squared_error: 0.2283 - val_loss: 30.3128 - val_mean_squared_error: 0.2993\n",
      "Epoch 25/200\n",
      "5839/5839 [==============================] - 1s 90us/step - loss: 28.9908 - mean_squared_error: 0.2319 - val_loss: 27.6933 - val_mean_squared_error: 0.3026\n",
      "Epoch 26/200\n",
      "5839/5839 [==============================] - 0s 85us/step - loss: 26.4378 - mean_squared_error: 0.2358 - val_loss: 25.2074 - val_mean_squared_error: 0.2979\n",
      "Epoch 27/200\n",
      "5839/5839 [==============================] - 0s 85us/step - loss: 24.0252 - mean_squared_error: 0.2405 - val_loss: 22.8658 - val_mean_squared_error: 0.2992\n",
      "Epoch 28/200\n",
      "5839/5839 [==============================] - 1s 91us/step - loss: 21.7509 - mean_squared_error: 0.2443 - val_loss: 20.6632 - val_mean_squared_error: 0.3049\n",
      "Epoch 29/200\n",
      "5839/5839 [==============================] - 1s 89us/step - loss: 19.6186 - mean_squared_error: 0.2506 - val_loss: 18.6030 - val_mean_squared_error: 0.3089\n",
      "Epoch 30/200\n",
      "5839/5839 [==============================] - 1s 94us/step - loss: 17.6261 - mean_squared_error: 0.2565 - val_loss: 16.6788 - val_mean_squared_error: 0.3089\n",
      "Epoch 31/200\n",
      "5839/5839 [==============================] - 0s 84us/step - loss: 15.7694 - mean_squared_error: 0.2611 - val_loss: 14.8945 - val_mean_squared_error: 0.3138\n",
      "Epoch 32/200\n",
      "5839/5839 [==============================] - 0s 85us/step - loss: 14.0527 - mean_squared_error: 0.2679 - val_loss: 13.2493 - val_mean_squared_error: 0.3165\n",
      "Epoch 33/200\n",
      "5839/5839 [==============================] - 1s 88us/step - loss: 12.4724 - mean_squared_error: 0.2734 - val_loss: 11.7385 - val_mean_squared_error: 0.3231\n",
      "Epoch 34/200\n",
      "5839/5839 [==============================] - 1s 89us/step - loss: 11.0274 - mean_squared_error: 0.2787 - val_loss: 10.3656 - val_mean_squared_error: 0.3320\n",
      "Epoch 35/200\n",
      "5839/5839 [==============================] - 0s 84us/step - loss: 9.7170 - mean_squared_error: 0.2836 - val_loss: 9.1226 - val_mean_squared_error: 0.3323\n",
      "Epoch 36/200\n",
      "5839/5839 [==============================] - 1s 91us/step - loss: 8.5393 - mean_squared_error: 0.2871 - val_loss: 8.0148 - val_mean_squared_error: 0.3379\n",
      "Epoch 37/200\n",
      "5839/5839 [==============================] - 0s 83us/step - loss: 7.4919 - mean_squared_error: 0.2902 - val_loss: 7.0320 - val_mean_squared_error: 0.3344\n",
      "Epoch 38/200\n",
      "5839/5839 [==============================] - 0s 82us/step - loss: 6.5731 - mean_squared_error: 0.2916 - val_loss: 6.1812 - val_mean_squared_error: 0.3376\n",
      "Epoch 39/200\n",
      "5839/5839 [==============================] - 0s 81us/step - loss: 5.7797 - mean_squared_error: 0.2925 - val_loss: 5.4419 - val_mean_squared_error: 0.3338\n",
      "Epoch 40/200\n",
      "5839/5839 [==============================] - 0s 82us/step - loss: 5.0773 - mean_squared_error: 0.2926 - val_loss: 4.7720 - val_mean_squared_error: 0.3334\n",
      "Epoch 41/200\n",
      "5839/5839 [==============================] - 0s 81us/step - loss: 4.4363 - mean_squared_error: 0.2909 - val_loss: 4.1639 - val_mean_squared_error: 0.3331\n",
      "Epoch 42/200\n",
      "5839/5839 [==============================] - 0s 82us/step - loss: 3.8566 - mean_squared_error: 0.2903 - val_loss: 3.6143 - val_mean_squared_error: 0.3325\n",
      "Epoch 43/200\n",
      "5839/5839 [==============================] - 0s 79us/step - loss: 3.3340 - mean_squared_error: 0.2882 - val_loss: 3.1295 - val_mean_squared_error: 0.3364\n",
      "Epoch 44/200\n",
      "5839/5839 [==============================] - 0s 80us/step - loss: 2.8728 - mean_squared_error: 0.2873 - val_loss: 2.6946 - val_mean_squared_error: 0.3306\n",
      "Epoch 45/200\n",
      "5839/5839 [==============================] - 0s 83us/step - loss: 2.4704 - mean_squared_error: 0.2854 - val_loss: 2.3247 - val_mean_squared_error: 0.3292\n",
      "Epoch 46/200\n",
      "5839/5839 [==============================] - 0s 81us/step - loss: 2.1285 - mean_squared_error: 0.2843 - val_loss: 2.0084 - val_mean_squared_error: 0.3240\n",
      "Epoch 47/200\n",
      "5839/5839 [==============================] - 0s 82us/step - loss: 1.8418 - mean_squared_error: 0.2830 - val_loss: 1.7523 - val_mean_squared_error: 0.3253\n",
      "Epoch 48/200\n",
      "5839/5839 [==============================] - 0s 81us/step - loss: 1.6058 - mean_squared_error: 0.2816 - val_loss: 1.5391 - val_mean_squared_error: 0.3250\n",
      "Epoch 49/200\n",
      "5839/5839 [==============================] - 0s 79us/step - loss: 1.4068 - mean_squared_error: 0.2812 - val_loss: 1.3534 - val_mean_squared_error: 0.3208\n",
      "Epoch 50/200\n",
      "5839/5839 [==============================] - 0s 77us/step - loss: 1.2369 - mean_squared_error: 0.2794 - val_loss: 1.1994 - val_mean_squared_error: 0.3197\n",
      "Epoch 51/200\n",
      "5839/5839 [==============================] - 0s 77us/step - loss: 1.0962 - mean_squared_error: 0.2783 - val_loss: 1.0733 - val_mean_squared_error: 0.3205\n",
      "Epoch 52/200\n",
      "5839/5839 [==============================] - 0s 77us/step - loss: 0.9805 - mean_squared_error: 0.2773 - val_loss: 0.9716 - val_mean_squared_error: 0.3190\n",
      "Epoch 53/200\n",
      "5839/5839 [==============================] - 0s 77us/step - loss: 0.8901 - mean_squared_error: 0.2749 - val_loss: 0.8946 - val_mean_squared_error: 0.3171\n",
      "Epoch 54/200\n",
      "5839/5839 [==============================] - 0s 76us/step - loss: 0.8240 - mean_squared_error: 0.2731 - val_loss: 0.8402 - val_mean_squared_error: 0.3157\n",
      "Epoch 55/200\n",
      "5839/5839 [==============================] - 0s 78us/step - loss: 0.7773 - mean_squared_error: 0.2712 - val_loss: 0.8011 - val_mean_squared_error: 0.3127\n",
      "Epoch 56/200\n",
      "5839/5839 [==============================] - 0s 78us/step - loss: 0.7434 - mean_squared_error: 0.2690 - val_loss: 0.7722 - val_mean_squared_error: 0.3127\n",
      "Epoch 57/200\n",
      "5839/5839 [==============================] - 0s 78us/step - loss: 0.7163 - mean_squared_error: 0.2673 - val_loss: 0.7471 - val_mean_squared_error: 0.3087\n",
      "Epoch 58/200\n",
      "5839/5839 [==============================] - 0s 80us/step - loss: 0.6929 - mean_squared_error: 0.2645 - val_loss: 0.7262 - val_mean_squared_error: 0.3071\n",
      "Epoch 59/200\n",
      "5839/5839 [==============================] - 0s 80us/step - loss: 0.6730 - mean_squared_error: 0.2618 - val_loss: 0.7076 - val_mean_squared_error: 0.3050\n",
      "Epoch 60/200\n",
      "5839/5839 [==============================] - 0s 83us/step - loss: 0.6559 - mean_squared_error: 0.2595 - val_loss: 0.6916 - val_mean_squared_error: 0.3025\n",
      "Epoch 61/200\n",
      "5839/5839 [==============================] - 0s 79us/step - loss: 0.6408 - mean_squared_error: 0.2574 - val_loss: 0.6791 - val_mean_squared_error: 0.3010\n",
      "Epoch 62/200\n",
      "5839/5839 [==============================] - 0s 82us/step - loss: 0.6273 - mean_squared_error: 0.2546 - val_loss: 0.6621 - val_mean_squared_error: 0.2948\n",
      "Epoch 63/200\n",
      "5839/5839 [==============================] - 0s 81us/step - loss: 0.6143 - mean_squared_error: 0.2514 - val_loss: 0.6505 - val_mean_squared_error: 0.2922\n",
      "Epoch 64/200\n",
      "5839/5839 [==============================] - 0s 82us/step - loss: 0.6035 - mean_squared_error: 0.2489 - val_loss: 0.6385 - val_mean_squared_error: 0.2880\n",
      "Epoch 65/200\n",
      "5839/5839 [==============================] - 0s 81us/step - loss: 0.5930 - mean_squared_error: 0.2460 - val_loss: 0.6283 - val_mean_squared_error: 0.2854\n",
      "Epoch 66/200\n",
      "5839/5839 [==============================] - 1s 97us/step - loss: 0.5833 - mean_squared_error: 0.2432 - val_loss: 0.6195 - val_mean_squared_error: 0.2833\n",
      "Epoch 67/200\n",
      "5839/5839 [==============================] - 0s 82us/step - loss: 0.5748 - mean_squared_error: 0.2412 - val_loss: 0.6095 - val_mean_squared_error: 0.2791\n",
      "Epoch 68/200\n",
      "5839/5839 [==============================] - 0s 83us/step - loss: 0.5664 - mean_squared_error: 0.2382 - val_loss: 0.5999 - val_mean_squared_error: 0.2744\n",
      "Epoch 69/200\n",
      "5839/5839 [==============================] - 0s 82us/step - loss: 0.5588 - mean_squared_error: 0.2357 - val_loss: 0.5926 - val_mean_squared_error: 0.2724\n",
      "Epoch 70/200\n",
      "5839/5839 [==============================] - 0s 85us/step - loss: 0.5520 - mean_squared_error: 0.2340 - val_loss: 0.5873 - val_mean_squared_error: 0.2708\n",
      "Epoch 71/200\n",
      "5839/5839 [==============================] - 0s 81us/step - loss: 0.5458 - mean_squared_error: 0.2316 - val_loss: 0.5792 - val_mean_squared_error: 0.2670\n",
      "Epoch 72/200\n",
      "5839/5839 [==============================] - 0s 82us/step - loss: 0.5401 - mean_squared_error: 0.2299 - val_loss: 0.5769 - val_mean_squared_error: 0.2684\n",
      "Epoch 73/200\n",
      "5839/5839 [==============================] - 1s 117us/step - loss: 0.5349 - mean_squared_error: 0.2283 - val_loss: 0.5671 - val_mean_squared_error: 0.2625\n",
      "Epoch 74/200\n",
      "5839/5839 [==============================] - 1s 137us/step - loss: 0.5298 - mean_squared_error: 0.2269 - val_loss: 0.5627 - val_mean_squared_error: 0.2608\n",
      "Epoch 75/200\n",
      "5839/5839 [==============================] - 1s 122us/step - loss: 0.5251 - mean_squared_error: 0.2250 - val_loss: 0.5563 - val_mean_squared_error: 0.2583\n",
      "Epoch 76/200\n",
      "5839/5839 [==============================] - 1s 114us/step - loss: 0.5203 - mean_squared_error: 0.2237 - val_loss: 0.5518 - val_mean_squared_error: 0.2570\n",
      "Epoch 77/200\n",
      "5839/5839 [==============================] - 1s 114us/step - loss: 0.5162 - mean_squared_error: 0.2227 - val_loss: 0.5463 - val_mean_squared_error: 0.2541\n",
      "Epoch 78/200\n",
      "5839/5839 [==============================] - 1s 92us/step - loss: 0.5129 - mean_squared_error: 0.2224 - val_loss: 0.5428 - val_mean_squared_error: 0.2531\n",
      "Epoch 79/200\n",
      "5839/5839 [==============================] - 1s 97us/step - loss: 0.5091 - mean_squared_error: 0.2209 - val_loss: 0.5385 - val_mean_squared_error: 0.2519\n",
      "Epoch 80/200\n",
      "5839/5839 [==============================] - 0s 85us/step - loss: 0.5054 - mean_squared_error: 0.2196 - val_loss: 0.5374 - val_mean_squared_error: 0.2535\n",
      "Epoch 81/200\n",
      "5839/5839 [==============================] - 1s 89us/step - loss: 0.5032 - mean_squared_error: 0.2203 - val_loss: 0.5324 - val_mean_squared_error: 0.2508\n",
      "Epoch 82/200\n",
      "5839/5839 [==============================] - 1s 112us/step - loss: 0.4993 - mean_squared_error: 0.2184 - val_loss: 0.5289 - val_mean_squared_error: 0.2486\n",
      "Epoch 83/200\n",
      "5839/5839 [==============================] - 1s 97us/step - loss: 0.4972 - mean_squared_error: 0.2184 - val_loss: 0.5256 - val_mean_squared_error: 0.2479\n",
      "Epoch 84/200\n",
      "5839/5839 [==============================] - 1s 87us/step - loss: 0.4945 - mean_squared_error: 0.2177 - val_loss: 0.5231 - val_mean_squared_error: 0.2477\n",
      "Epoch 85/200\n",
      "5839/5839 [==============================] - 1s 88us/step - loss: 0.4914 - mean_squared_error: 0.2167 - val_loss: 0.5196 - val_mean_squared_error: 0.2451\n",
      "Epoch 86/200\n",
      "5839/5839 [==============================] - 1s 87us/step - loss: 0.4903 - mean_squared_error: 0.2170 - val_loss: 0.5181 - val_mean_squared_error: 0.2468\n",
      "Epoch 87/200\n",
      "5839/5839 [==============================] - 1s 98us/step - loss: 0.4876 - mean_squared_error: 0.2163 - val_loss: 0.5190 - val_mean_squared_error: 0.2489\n",
      "Epoch 88/200\n",
      "5839/5839 [==============================] - 1s 93us/step - loss: 0.4853 - mean_squared_error: 0.2158 - val_loss: 0.5131 - val_mean_squared_error: 0.2445\n",
      "Epoch 89/200\n",
      "5839/5839 [==============================] - 1s 92us/step - loss: 0.4836 - mean_squared_error: 0.2156 - val_loss: 0.5175 - val_mean_squared_error: 0.2509\n",
      "Epoch 90/200\n",
      "5839/5839 [==============================] - 1s 93us/step - loss: 0.4808 - mean_squared_error: 0.2147 - val_loss: 0.5099 - val_mean_squared_error: 0.2450\n",
      "Epoch 91/200\n",
      "5839/5839 [==============================] - 1s 87us/step - loss: 0.4801 - mean_squared_error: 0.2153 - val_loss: 0.5085 - val_mean_squared_error: 0.2450\n",
      "Epoch 92/200\n",
      "5839/5839 [==============================] - 1s 88us/step - loss: 0.4775 - mean_squared_error: 0.2144 - val_loss: 0.5045 - val_mean_squared_error: 0.2428\n",
      "Epoch 93/200\n",
      "5839/5839 [==============================] - 1s 88us/step - loss: 0.4762 - mean_squared_error: 0.2148 - val_loss: 0.5029 - val_mean_squared_error: 0.2426\n",
      "Epoch 94/200\n",
      "5839/5839 [==============================] - 1s 88us/step - loss: 0.4742 - mean_squared_error: 0.2142 - val_loss: 0.5000 - val_mean_squared_error: 0.2413\n",
      "Epoch 95/200\n",
      "5839/5839 [==============================] - 1s 87us/step - loss: 0.4724 - mean_squared_error: 0.2143 - val_loss: 0.4996 - val_mean_squared_error: 0.2419\n",
      "Epoch 96/200\n",
      "5839/5839 [==============================] - 1s 87us/step - loss: 0.4709 - mean_squared_error: 0.2138 - val_loss: 0.4988 - val_mean_squared_error: 0.2427\n",
      "Epoch 97/200\n",
      "5839/5839 [==============================] - 1s 104us/step - loss: 0.4698 - mean_squared_error: 0.2142 - val_loss: 0.4980 - val_mean_squared_error: 0.2436\n",
      "Epoch 98/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5839/5839 [==============================] - 1s 116us/step - loss: 0.4684 - mean_squared_error: 0.2142 - val_loss: 0.4961 - val_mean_squared_error: 0.2425\n",
      "Epoch 99/200\n",
      "5839/5839 [==============================] - 1s 134us/step - loss: 0.4661 - mean_squared_error: 0.2129 - val_loss: 0.4949 - val_mean_squared_error: 0.2429\n",
      "Epoch 100/200\n",
      "5839/5839 [==============================] - 1s 89us/step - loss: 0.4654 - mean_squared_error: 0.2135 - val_loss: 0.4940 - val_mean_squared_error: 0.2431\n",
      "Epoch 101/200\n",
      "5839/5839 [==============================] - 0s 85us/step - loss: 0.4641 - mean_squared_error: 0.2135 - val_loss: 0.4927 - val_mean_squared_error: 0.2422\n",
      "Epoch 102/200\n",
      "5839/5839 [==============================] - 1s 130us/step - loss: 0.4631 - mean_squared_error: 0.2134 - val_loss: 0.4958 - val_mean_squared_error: 0.2453\n",
      "Epoch 103/200\n",
      "5839/5839 [==============================] - 1s 91us/step - loss: 0.4621 - mean_squared_error: 0.2133 - val_loss: 0.4916 - val_mean_squared_error: 0.2441\n",
      "Epoch 104/200\n",
      "5839/5839 [==============================] - 1s 106us/step - loss: 0.4609 - mean_squared_error: 0.2134 - val_loss: 0.4911 - val_mean_squared_error: 0.2440\n",
      "Epoch 105/200\n",
      "5839/5839 [==============================] - 1s 95us/step - loss: 0.4594 - mean_squared_error: 0.2127 - val_loss: 0.4880 - val_mean_squared_error: 0.2416\n",
      "Epoch 106/200\n",
      "5839/5839 [==============================] - 1s 98us/step - loss: 0.4588 - mean_squared_error: 0.2130 - val_loss: 0.4878 - val_mean_squared_error: 0.2417\n",
      "Epoch 107/200\n",
      "5839/5839 [==============================] - 1s 89us/step - loss: 0.4577 - mean_squared_error: 0.2125 - val_loss: 0.4866 - val_mean_squared_error: 0.2416\n",
      "Epoch 108/200\n",
      "5839/5839 [==============================] - 1s 108us/step - loss: 0.4567 - mean_squared_error: 0.2123 - val_loss: 0.4900 - val_mean_squared_error: 0.2463\n",
      "Epoch 109/200\n",
      "5839/5839 [==============================] - 0s 85us/step - loss: 0.4561 - mean_squared_error: 0.2128 - val_loss: 0.4838 - val_mean_squared_error: 0.2406\n",
      "Epoch 110/200\n",
      "5839/5839 [==============================] - 1s 106us/step - loss: 0.4555 - mean_squared_error: 0.2128 - val_loss: 0.4839 - val_mean_squared_error: 0.2419\n",
      "Epoch 111/200\n",
      "5839/5839 [==============================] - 1s 88us/step - loss: 0.4541 - mean_squared_error: 0.2123 - val_loss: 0.4829 - val_mean_squared_error: 0.2409\n",
      "Epoch 112/200\n",
      "5839/5839 [==============================] - 1s 98us/step - loss: 0.4535 - mean_squared_error: 0.2122 - val_loss: 0.4842 - val_mean_squared_error: 0.2434\n",
      "Epoch 113/200\n",
      "5839/5839 [==============================] - 1s 94us/step - loss: 0.4541 - mean_squared_error: 0.2137 - val_loss: 0.4816 - val_mean_squared_error: 0.2411\n",
      "Epoch 114/200\n",
      "5839/5839 [==============================] - 1s 96us/step - loss: 0.4525 - mean_squared_error: 0.2129 - val_loss: 0.4812 - val_mean_squared_error: 0.2422\n",
      "Epoch 115/200\n",
      "5839/5839 [==============================] - 1s 98us/step - loss: 0.4512 - mean_squared_error: 0.2123 - val_loss: 0.4819 - val_mean_squared_error: 0.2435\n",
      "Epoch 116/200\n",
      "5839/5839 [==============================] - 1s 107us/step - loss: 0.4513 - mean_squared_error: 0.2132 - val_loss: 0.4792 - val_mean_squared_error: 0.2415\n",
      "Epoch 117/200\n",
      "5839/5839 [==============================] - 1s 105us/step - loss: 0.4497 - mean_squared_error: 0.2123 - val_loss: 0.4774 - val_mean_squared_error: 0.2402\n",
      "Epoch 118/200\n",
      "5839/5839 [==============================] - 1s 111us/step - loss: 0.4492 - mean_squared_error: 0.2125 - val_loss: 0.4781 - val_mean_squared_error: 0.2415\n",
      "Epoch 119/200\n",
      "5839/5839 [==============================] - 1s 96us/step - loss: 0.4483 - mean_squared_error: 0.2120 - val_loss: 0.4782 - val_mean_squared_error: 0.2419\n",
      "Epoch 120/200\n",
      "5839/5839 [==============================] - 1s 102us/step - loss: 0.4483 - mean_squared_error: 0.2127 - val_loss: 0.4776 - val_mean_squared_error: 0.2427\n",
      "Epoch 121/200\n",
      "5839/5839 [==============================] - 1s 96us/step - loss: 0.4474 - mean_squared_error: 0.2124 - val_loss: 0.4781 - val_mean_squared_error: 0.2432\n",
      "Epoch 122/200\n",
      "5839/5839 [==============================] - 1s 99us/step - loss: 0.4465 - mean_squared_error: 0.2118 - val_loss: 0.4761 - val_mean_squared_error: 0.2426\n",
      "Epoch 123/200\n",
      "5839/5839 [==============================] - 1s 111us/step - loss: 0.4465 - mean_squared_error: 0.2128 - val_loss: 0.4752 - val_mean_squared_error: 0.2413\n",
      "Epoch 124/200\n",
      "5839/5839 [==============================] - 1s 110us/step - loss: 0.4458 - mean_squared_error: 0.2126 - val_loss: 0.4733 - val_mean_squared_error: 0.2405\n",
      "Epoch 125/200\n",
      "5839/5839 [==============================] - 1s 98us/step - loss: 0.4451 - mean_squared_error: 0.2126 - val_loss: 0.4755 - val_mean_squared_error: 0.2434\n",
      "Epoch 126/200\n",
      "5839/5839 [==============================] - 1s 117us/step - loss: 0.4448 - mean_squared_error: 0.2126 - val_loss: 0.4721 - val_mean_squared_error: 0.2402\n",
      "Epoch 127/200\n",
      "5839/5839 [==============================] - 1s 114us/step - loss: 0.4446 - mean_squared_error: 0.2127 - val_loss: 0.4765 - val_mean_squared_error: 0.2455\n",
      "Epoch 128/200\n",
      "5839/5839 [==============================] - 1s 99us/step - loss: 0.4441 - mean_squared_error: 0.2128 - val_loss: 0.4750 - val_mean_squared_error: 0.2436\n",
      "Epoch 129/200\n",
      "5839/5839 [==============================] - 1s 102us/step - loss: 0.4428 - mean_squared_error: 0.2119 - val_loss: 0.4748 - val_mean_squared_error: 0.2445\n",
      "Epoch 130/200\n",
      "5839/5839 [==============================] - 1s 106us/step - loss: 0.4423 - mean_squared_error: 0.2123 - val_loss: 0.4728 - val_mean_squared_error: 0.2414\n",
      "Epoch 131/200\n",
      "5839/5839 [==============================] - 1s 112us/step - loss: 0.4415 - mean_squared_error: 0.2114 - val_loss: 0.4721 - val_mean_squared_error: 0.2428\n",
      "Epoch 132/200\n",
      "5839/5839 [==============================] - 1s 101us/step - loss: 0.4413 - mean_squared_error: 0.2120 - val_loss: 0.4695 - val_mean_squared_error: 0.2406\n",
      "Epoch 133/200\n",
      "5839/5839 [==============================] - 1s 107us/step - loss: 0.4417 - mean_squared_error: 0.2128 - val_loss: 0.4707 - val_mean_squared_error: 0.2427\n",
      "Epoch 134/200\n",
      "5839/5839 [==============================] - 1s 100us/step - loss: 0.4405 - mean_squared_error: 0.2122 - val_loss: 0.4710 - val_mean_squared_error: 0.2420\n",
      "Epoch 135/200\n",
      "5839/5839 [==============================] - 1s 106us/step - loss: 0.4397 - mean_squared_error: 0.2118 - val_loss: 0.4702 - val_mean_squared_error: 0.2428\n",
      "Epoch 136/200\n",
      "5839/5839 [==============================] - 1s 101us/step - loss: 0.4396 - mean_squared_error: 0.2122 - val_loss: 0.4699 - val_mean_squared_error: 0.2430\n",
      "Epoch 137/200\n",
      "5839/5839 [==============================] - 1s 100us/step - loss: 0.4394 - mean_squared_error: 0.2123 - val_loss: 0.4688 - val_mean_squared_error: 0.2417\n",
      "Epoch 138/200\n",
      "5839/5839 [==============================] - 1s 125us/step - loss: 0.4389 - mean_squared_error: 0.2120 - val_loss: 0.4682 - val_mean_squared_error: 0.2422\n",
      "Epoch 139/200\n",
      "5839/5839 [==============================] - 1s 96us/step - loss: 0.4385 - mean_squared_error: 0.2121 - val_loss: 0.4684 - val_mean_squared_error: 0.2424\n",
      "Epoch 140/200\n",
      "5839/5839 [==============================] - 1s 116us/step - loss: 0.4383 - mean_squared_error: 0.2125 - val_loss: 0.4675 - val_mean_squared_error: 0.2415\n",
      "Epoch 141/200\n",
      "5839/5839 [==============================] - 1s 101us/step - loss: 0.4384 - mean_squared_error: 0.2129 - val_loss: 0.4676 - val_mean_squared_error: 0.2422\n",
      "Epoch 142/200\n",
      "5839/5839 [==============================] - 1s 94us/step - loss: 0.4382 - mean_squared_error: 0.2131 - val_loss: 0.4691 - val_mean_squared_error: 0.2433\n",
      "Epoch 143/200\n",
      "5839/5839 [==============================] - 1s 90us/step - loss: 0.4368 - mean_squared_error: 0.2119 - val_loss: 0.4653 - val_mean_squared_error: 0.2408\n",
      "Epoch 144/200\n",
      "5839/5839 [==============================] - 1s 88us/step - loss: 0.4365 - mean_squared_error: 0.2123 - val_loss: 0.4641 - val_mean_squared_error: 0.2397\n",
      "Epoch 145/200\n",
      "5839/5839 [==============================] - 1s 93us/step - loss: 0.4360 - mean_squared_error: 0.2121 - val_loss: 0.4655 - val_mean_squared_error: 0.2419\n",
      "Epoch 146/200\n",
      "5839/5839 [==============================] - 1s 122us/step - loss: 0.4360 - mean_squared_error: 0.2124 - val_loss: 0.4647 - val_mean_squared_error: 0.2413\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 147/200\n",
      "5839/5839 [==============================] - 1s 103us/step - loss: 0.4356 - mean_squared_error: 0.2122 - val_loss: 0.4632 - val_mean_squared_error: 0.2396\n",
      "Epoch 148/200\n",
      "5839/5839 [==============================] - 1s 119us/step - loss: 0.4348 - mean_squared_error: 0.2119 - val_loss: 0.4651 - val_mean_squared_error: 0.2411\n",
      "Epoch 149/200\n",
      "5839/5839 [==============================] - 1s 118us/step - loss: 0.4353 - mean_squared_error: 0.2126 - val_loss: 0.4648 - val_mean_squared_error: 0.2426\n",
      "Epoch 150/200\n",
      "5839/5839 [==============================] - 1s 118us/step - loss: 0.4346 - mean_squared_error: 0.2124 - val_loss: 0.4658 - val_mean_squared_error: 0.2440\n",
      "Epoch 151/200\n",
      "5839/5839 [==============================] - 1s 118us/step - loss: 0.4346 - mean_squared_error: 0.2124 - val_loss: 0.4634 - val_mean_squared_error: 0.2419\n",
      "Epoch 152/200\n",
      "5839/5839 [==============================] - 1s 123us/step - loss: 0.4337 - mean_squared_error: 0.2121 - val_loss: 0.4638 - val_mean_squared_error: 0.2422\n",
      "Epoch 153/200\n",
      "5839/5839 [==============================] - 1s 119us/step - loss: 0.4333 - mean_squared_error: 0.2119 - val_loss: 0.4634 - val_mean_squared_error: 0.2414\n",
      "Epoch 154/200\n",
      "5839/5839 [==============================] - 1s 123us/step - loss: 0.4333 - mean_squared_error: 0.2123 - val_loss: 0.4644 - val_mean_squared_error: 0.2430\n",
      "Epoch 155/200\n",
      "5839/5839 [==============================] - 1s 122us/step - loss: 0.4331 - mean_squared_error: 0.2120 - val_loss: 0.4612 - val_mean_squared_error: 0.2400\n",
      "Epoch 156/200\n",
      "5839/5839 [==============================] - 1s 128us/step - loss: 0.4332 - mean_squared_error: 0.2125 - val_loss: 0.4624 - val_mean_squared_error: 0.2409\n",
      "Epoch 157/200\n",
      "5839/5839 [==============================] - 1s 126us/step - loss: 0.4326 - mean_squared_error: 0.2120 - val_loss: 0.4646 - val_mean_squared_error: 0.2445\n",
      "Epoch 158/200\n",
      "5839/5839 [==============================] - 1s 128us/step - loss: 0.4323 - mean_squared_error: 0.2118 - val_loss: 0.4621 - val_mean_squared_error: 0.2426\n",
      "Epoch 159/200\n",
      "5839/5839 [==============================] - 1s 128us/step - loss: 0.4323 - mean_squared_error: 0.2126 - val_loss: 0.4611 - val_mean_squared_error: 0.2414\n",
      "Epoch 160/200\n",
      "5839/5839 [==============================] - 1s 143us/step - loss: 0.4314 - mean_squared_error: 0.2116 - val_loss: 0.4612 - val_mean_squared_error: 0.2422\n",
      "Epoch 161/200\n",
      "5839/5839 [==============================] - 1s 125us/step - loss: 0.4315 - mean_squared_error: 0.2122 - val_loss: 0.4588 - val_mean_squared_error: 0.2395\n",
      "Epoch 162/200\n",
      "5839/5839 [==============================] - 1s 127us/step - loss: 0.4316 - mean_squared_error: 0.2125 - val_loss: 0.4601 - val_mean_squared_error: 0.2410\n",
      "Epoch 163/200\n",
      "5839/5839 [==============================] - 1s 100us/step - loss: 0.4316 - mean_squared_error: 0.2126 - val_loss: 0.4607 - val_mean_squared_error: 0.2408\n",
      "Epoch 164/200\n",
      "5839/5839 [==============================] - 1s 99us/step - loss: 0.4311 - mean_squared_error: 0.2123 - val_loss: 0.4605 - val_mean_squared_error: 0.2424\n",
      "Epoch 165/200\n",
      "5839/5839 [==============================] - 1s 88us/step - loss: 0.4301 - mean_squared_error: 0.2118 - val_loss: 0.4591 - val_mean_squared_error: 0.2406\n",
      "Epoch 166/200\n",
      "5839/5839 [==============================] - 1s 86us/step - loss: 0.4302 - mean_squared_error: 0.2116 - val_loss: 0.4601 - val_mean_squared_error: 0.2413\n",
      "Epoch 167/200\n",
      "5839/5839 [==============================] - 1s 87us/step - loss: 0.4298 - mean_squared_error: 0.2117 - val_loss: 0.4603 - val_mean_squared_error: 0.2424\n",
      "Epoch 168/200\n",
      "5839/5839 [==============================] - 1s 89us/step - loss: 0.4299 - mean_squared_error: 0.2121 - val_loss: 0.4601 - val_mean_squared_error: 0.2422\n",
      "Epoch 169/200\n",
      "5839/5839 [==============================] - 1s 91us/step - loss: 0.4294 - mean_squared_error: 0.2115 - val_loss: 0.4698 - val_mean_squared_error: 0.2512\n",
      "Epoch 170/200\n",
      "5839/5839 [==============================] - 1s 88us/step - loss: 0.4298 - mean_squared_error: 0.2125 - val_loss: 0.4618 - val_mean_squared_error: 0.2445\n",
      "Epoch 171/200\n",
      "5839/5839 [==============================] - 1s 87us/step - loss: 0.4289 - mean_squared_error: 0.2116 - val_loss: 0.4584 - val_mean_squared_error: 0.2418\n",
      "Epoch 172/200\n",
      "5839/5839 [==============================] - 1s 86us/step - loss: 0.4287 - mean_squared_error: 0.2117 - val_loss: 0.4608 - val_mean_squared_error: 0.2444\n",
      "Epoch 173/200\n",
      "5839/5839 [==============================] - 1s 90us/step - loss: 0.4288 - mean_squared_error: 0.2120 - val_loss: 0.4584 - val_mean_squared_error: 0.2406\n",
      "Epoch 174/200\n",
      "5839/5839 [==============================] - 1s 90us/step - loss: 0.4289 - mean_squared_error: 0.2123 - val_loss: 0.4582 - val_mean_squared_error: 0.2416\n",
      "Epoch 175/200\n",
      "5839/5839 [==============================] - 1s 88us/step - loss: 0.4283 - mean_squared_error: 0.2116 - val_loss: 0.4578 - val_mean_squared_error: 0.2418\n",
      "Epoch 176/200\n",
      "5839/5839 [==============================] - 1s 90us/step - loss: 0.4277 - mean_squared_error: 0.2115 - val_loss: 0.4597 - val_mean_squared_error: 0.2435\n",
      "Epoch 177/200\n",
      "5839/5839 [==============================] - 1s 88us/step - loss: 0.4276 - mean_squared_error: 0.2115 - val_loss: 0.4574 - val_mean_squared_error: 0.2414\n",
      "Epoch 178/200\n",
      "5839/5839 [==============================] - 1s 88us/step - loss: 0.4274 - mean_squared_error: 0.2113 - val_loss: 0.4568 - val_mean_squared_error: 0.2411\n",
      "Epoch 179/200\n",
      "5839/5839 [==============================] - 1s 88us/step - loss: 0.4278 - mean_squared_error: 0.2120 - val_loss: 0.4573 - val_mean_squared_error: 0.2414\n",
      "Epoch 180/200\n",
      "5839/5839 [==============================] - 1s 88us/step - loss: 0.4270 - mean_squared_error: 0.2116 - val_loss: 0.4564 - val_mean_squared_error: 0.2410\n",
      "Epoch 181/200\n",
      "5839/5839 [==============================] - 1s 88us/step - loss: 0.4270 - mean_squared_error: 0.2116 - val_loss: 0.4556 - val_mean_squared_error: 0.2406\n",
      "Epoch 182/200\n",
      "5839/5839 [==============================] - 1s 88us/step - loss: 0.4277 - mean_squared_error: 0.2126 - val_loss: 0.4563 - val_mean_squared_error: 0.2412\n",
      "Epoch 183/200\n",
      "5839/5839 [==============================] - 1s 88us/step - loss: 0.4262 - mean_squared_error: 0.2112 - val_loss: 0.4560 - val_mean_squared_error: 0.2411\n",
      "Epoch 184/200\n",
      "5839/5839 [==============================] - 1s 89us/step - loss: 0.4264 - mean_squared_error: 0.2117 - val_loss: 0.4576 - val_mean_squared_error: 0.2434\n",
      "Epoch 185/200\n",
      "5839/5839 [==============================] - 1s 88us/step - loss: 0.4260 - mean_squared_error: 0.2116 - val_loss: 0.4604 - val_mean_squared_error: 0.2462\n",
      "Epoch 186/200\n",
      "5839/5839 [==============================] - 1s 90us/step - loss: 0.4284 - mean_squared_error: 0.2136 - val_loss: 0.4581 - val_mean_squared_error: 0.2430\n",
      "Epoch 187/200\n",
      "5839/5839 [==============================] - 1s 88us/step - loss: 0.4264 - mean_squared_error: 0.2124 - val_loss: 0.4598 - val_mean_squared_error: 0.2457\n",
      "Epoch 188/200\n",
      "5839/5839 [==============================] - 1s 89us/step - loss: 0.4264 - mean_squared_error: 0.2123 - val_loss: 0.4582 - val_mean_squared_error: 0.2428\n",
      "Epoch 189/200\n",
      "5839/5839 [==============================] - 1s 88us/step - loss: 0.4267 - mean_squared_error: 0.2126 - val_loss: 0.4601 - val_mean_squared_error: 0.2469\n",
      "Epoch 190/200\n",
      "5839/5839 [==============================] - 1s 90us/step - loss: 0.4254 - mean_squared_error: 0.2118 - val_loss: 0.4574 - val_mean_squared_error: 0.2442\n",
      "Epoch 191/200\n",
      "5839/5839 [==============================] - 1s 89us/step - loss: 0.4249 - mean_squared_error: 0.2113 - val_loss: 0.4545 - val_mean_squared_error: 0.2413\n",
      "Epoch 192/200\n",
      "5839/5839 [==============================] - 1s 90us/step - loss: 0.4256 - mean_squared_error: 0.2123 - val_loss: 0.4569 - val_mean_squared_error: 0.2437\n",
      "Epoch 193/200\n",
      "5839/5839 [==============================] - 1s 89us/step - loss: 0.4248 - mean_squared_error: 0.2115 - val_loss: 0.4562 - val_mean_squared_error: 0.2431\n",
      "Epoch 194/200\n",
      "5839/5839 [==============================] - 1s 89us/step - loss: 0.4253 - mean_squared_error: 0.2121 - val_loss: 0.4563 - val_mean_squared_error: 0.2433\n",
      "Epoch 195/200\n",
      "5839/5839 [==============================] - 1s 89us/step - loss: 0.4246 - mean_squared_error: 0.2118 - val_loss: 0.4567 - val_mean_squared_error: 0.2440\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 196/200\n",
      "5839/5839 [==============================] - 1s 87us/step - loss: 0.4252 - mean_squared_error: 0.2124 - val_loss: 0.4583 - val_mean_squared_error: 0.2457\n",
      "Epoch 197/200\n",
      "5839/5839 [==============================] - 1s 88us/step - loss: 0.4263 - mean_squared_error: 0.2135 - val_loss: 0.4535 - val_mean_squared_error: 0.2408\n",
      "Epoch 198/200\n",
      "5839/5839 [==============================] - 1s 88us/step - loss: 0.4248 - mean_squared_error: 0.2123 - val_loss: 0.4525 - val_mean_squared_error: 0.2401\n",
      "Epoch 199/200\n",
      "5839/5839 [==============================] - 1s 86us/step - loss: 0.4246 - mean_squared_error: 0.2123 - val_loss: 0.4561 - val_mean_squared_error: 0.2429\n",
      "Epoch 200/200\n",
      "5839/5839 [==============================] - 1s 87us/step - loss: 0.4247 - mean_squared_error: 0.2125 - val_loss: 0.4572 - val_mean_squared_error: 0.2446\n",
      "Training MSE: 0.2115\n",
      "Validation MSE: 0.1803\n",
      "\n",
      "Training r2: 0.6075\n",
      "Validation r2: 0.6395\n"
     ]
    }
   ],
   "source": [
    "nn4 = models.Sequential()\n",
    "nn4.add(layers.Dense(128, input_shape=(X_train.shape[1],), kernel_regularizer=regularizers.l1(0.01), activation='relu'))\n",
    "nn4.add(layers.Dense(256, kernel_regularizer=regularizers.l1(0.01), activation='relu'))\n",
    "nn4.add(layers.Dense(256, kernel_regularizer=regularizers.l1(0.01), activation='relu'))\n",
    "nn4.add(layers.Dense(512, kernel_regularizer=regularizers.l1(0.01), activation='relu'))\n",
    "nn4.add(layers.Dense(1, activation='linear'))\n",
    "\n",
    "# Compiling the model\n",
    "nn4.compile(loss='mean_squared_error',\n",
    "            optimizer='SGD',\n",
    "            metrics=['mean_squared_error'])\n",
    "\n",
    "nn4_history = nn4.fit(X_train,\n",
    "                  y_train,\n",
    "                  epochs=200,\n",
    "                  batch_size=256,\n",
    "                  validation_split = 0.1)\n",
    "\n",
    "nn_model_evaluation(nn4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fresh-proportion",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5839 samples, validate on 649 samples\n",
      "Epoch 1/150\n",
      "5839/5839 [==============================] - 1s 119us/step - loss: 97.2004 - mean_squared_error: 8.6251 - val_loss: 81.0111 - val_mean_squared_error: 3.6832\n",
      "Epoch 2/150\n",
      "5839/5839 [==============================] - 0s 69us/step - loss: 69.8499 - mean_squared_error: 2.2149 - val_loss: 58.6920 - val_mean_squared_error: 1.2966\n",
      "Epoch 3/150\n",
      "5839/5839 [==============================] - 0s 68us/step - loss: 49.9368 - mean_squared_error: 0.7728 - val_loss: 41.4387 - val_mean_squared_error: 0.6272\n",
      "Epoch 4/150\n",
      "5839/5839 [==============================] - 0s 74us/step - loss: 35.2209 - mean_squared_error: 0.4096 - val_loss: 29.5018 - val_mean_squared_error: 0.4460\n",
      "Epoch 5/150\n",
      "5839/5839 [==============================] - 0s 69us/step - loss: 25.3989 - mean_squared_error: 0.3208 - val_loss: 21.6059 - val_mean_squared_error: 0.3887\n",
      "Epoch 6/150\n",
      "5839/5839 [==============================] - 0s 75us/step - loss: 18.7846 - mean_squared_error: 0.2764 - val_loss: 16.1824 - val_mean_squared_error: 0.3438\n",
      "Epoch 7/150\n",
      "5839/5839 [==============================] - 1s 93us/step - loss: 14.1622 - mean_squared_error: 0.2526 - val_loss: 12.3190 - val_mean_squared_error: 0.3249\n",
      "Epoch 8/150\n",
      "5839/5839 [==============================] - 0s 76us/step - loss: 10.8346 - mean_squared_error: 0.2369 - val_loss: 9.4898 - val_mean_squared_error: 0.2956\n",
      "Epoch 9/150\n",
      "5839/5839 [==============================] - 0s 85us/step - loss: 8.3841 - mean_squared_error: 0.2301 - val_loss: 7.3857 - val_mean_squared_error: 0.2791\n",
      "Epoch 10/150\n",
      "5839/5839 [==============================] - 1s 87us/step - loss: 6.5430 - mean_squared_error: 0.2247 - val_loss: 5.7946 - val_mean_squared_error: 0.2715\n",
      "Epoch 11/150\n",
      "5839/5839 [==============================] - 0s 72us/step - loss: 5.1499 - mean_squared_error: 0.2273 - val_loss: 4.5860 - val_mean_squared_error: 0.2711\n",
      "Epoch 12/150\n",
      "5839/5839 [==============================] - 0s 72us/step - loss: 4.0852 - mean_squared_error: 0.2354 - val_loss: 3.6640 - val_mean_squared_error: 0.2830\n",
      "Epoch 13/150\n",
      "5839/5839 [==============================] - 0s 70us/step - loss: 3.2728 - mean_squared_error: 0.2440 - val_loss: 2.9597 - val_mean_squared_error: 0.2877\n",
      "Epoch 14/150\n",
      "5839/5839 [==============================] - 0s 72us/step - loss: 2.6561 - mean_squared_error: 0.2505 - val_loss: 2.4323 - val_mean_squared_error: 0.2922\n",
      "Epoch 15/150\n",
      "5839/5839 [==============================] - 0s 72us/step - loss: 2.1953 - mean_squared_error: 0.2585 - val_loss: 2.0340 - val_mean_squared_error: 0.2979\n",
      "Epoch 16/150\n",
      "5839/5839 [==============================] - 0s 75us/step - loss: 1.8469 - mean_squared_error: 0.2604 - val_loss: 1.7324 - val_mean_squared_error: 0.3037\n",
      "Epoch 17/150\n",
      "5839/5839 [==============================] - 0s 74us/step - loss: 1.5783 - mean_squared_error: 0.2617 - val_loss: 1.5010 - val_mean_squared_error: 0.2998\n",
      "Epoch 18/150\n",
      "5839/5839 [==============================] - 0s 71us/step - loss: 1.3695 - mean_squared_error: 0.2604 - val_loss: 1.3187 - val_mean_squared_error: 0.2994\n",
      "Epoch 19/150\n",
      "5839/5839 [==============================] - 0s 73us/step - loss: 1.2062 - mean_squared_error: 0.2561 - val_loss: 1.1695 - val_mean_squared_error: 0.2919\n",
      "Epoch 20/150\n",
      "5839/5839 [==============================] - 0s 76us/step - loss: 1.0754 - mean_squared_error: 0.2509 - val_loss: 1.0551 - val_mean_squared_error: 0.2875\n",
      "Epoch 21/150\n",
      "5839/5839 [==============================] - 0s 71us/step - loss: 0.9712 - mean_squared_error: 0.2442 - val_loss: 0.9602 - val_mean_squared_error: 0.2780\n",
      "Epoch 22/150\n",
      "5839/5839 [==============================] - 0s 72us/step - loss: 0.8868 - mean_squared_error: 0.2397 - val_loss: 0.8798 - val_mean_squared_error: 0.2686\n",
      "Epoch 23/150\n",
      "5839/5839 [==============================] - 0s 72us/step - loss: 0.8199 - mean_squared_error: 0.2350 - val_loss: 0.8190 - val_mean_squared_error: 0.2640\n",
      "Epoch 24/150\n",
      "5839/5839 [==============================] - 0s 74us/step - loss: 0.7654 - mean_squared_error: 0.2314 - val_loss: 0.7752 - val_mean_squared_error: 0.2629\n",
      "Epoch 25/150\n",
      "5839/5839 [==============================] - 0s 75us/step - loss: 0.7260 - mean_squared_error: 0.2279 - val_loss: 0.7353 - val_mean_squared_error: 0.2549\n",
      "Epoch 26/150\n",
      "5839/5839 [==============================] - 0s 73us/step - loss: 0.6929 - mean_squared_error: 0.2253 - val_loss: 0.7096 - val_mean_squared_error: 0.2562\n",
      "Epoch 27/150\n",
      "5839/5839 [==============================] - 0s 72us/step - loss: 0.6670 - mean_squared_error: 0.2230 - val_loss: 0.6815 - val_mean_squared_error: 0.2498\n",
      "Epoch 28/150\n",
      "5839/5839 [==============================] - 0s 76us/step - loss: 0.6449 - mean_squared_error: 0.2201 - val_loss: 0.6622 - val_mean_squared_error: 0.2467\n",
      "Epoch 29/150\n",
      "5839/5839 [==============================] - 0s 78us/step - loss: 0.6273 - mean_squared_error: 0.2193 - val_loss: 0.6469 - val_mean_squared_error: 0.2467\n",
      "Epoch 30/150\n",
      "5839/5839 [==============================] - 0s 73us/step - loss: 0.6123 - mean_squared_error: 0.2180 - val_loss: 0.6377 - val_mean_squared_error: 0.2446\n",
      "Epoch 31/150\n",
      "5839/5839 [==============================] - 0s 78us/step - loss: 0.6035 - mean_squared_error: 0.2163 - val_loss: 0.6257 - val_mean_squared_error: 0.2452\n",
      "Epoch 32/150\n",
      "5839/5839 [==============================] - 0s 79us/step - loss: 0.5903 - mean_squared_error: 0.2155 - val_loss: 0.6109 - val_mean_squared_error: 0.2423\n",
      "Epoch 33/150\n",
      "5839/5839 [==============================] - 0s 75us/step - loss: 0.5807 - mean_squared_error: 0.2144 - val_loss: 0.6013 - val_mean_squared_error: 0.2398\n",
      "Epoch 34/150\n",
      "5839/5839 [==============================] - 0s 78us/step - loss: 0.5724 - mean_squared_error: 0.2138 - val_loss: 0.5945 - val_mean_squared_error: 0.2390\n",
      "Epoch 35/150\n",
      "5839/5839 [==============================] - 0s 73us/step - loss: 0.5663 - mean_squared_error: 0.2130 - val_loss: 0.5866 - val_mean_squared_error: 0.2374\n",
      "Epoch 36/150\n",
      "5839/5839 [==============================] - 0s 70us/step - loss: 0.5583 - mean_squared_error: 0.2119 - val_loss: 0.5803 - val_mean_squared_error: 0.2369\n",
      "Epoch 37/150\n",
      "5839/5839 [==============================] - 0s 69us/step - loss: 0.5524 - mean_squared_error: 0.2110 - val_loss: 0.5715 - val_mean_squared_error: 0.2340\n",
      "Epoch 38/150\n",
      "5839/5839 [==============================] - 0s 68us/step - loss: 0.5459 - mean_squared_error: 0.2107 - val_loss: 0.5777 - val_mean_squared_error: 0.2388\n",
      "Epoch 39/150\n",
      "5839/5839 [==============================] - 0s 68us/step - loss: 0.5449 - mean_squared_error: 0.2097 - val_loss: 0.5702 - val_mean_squared_error: 0.2384\n",
      "Epoch 40/150\n",
      "5839/5839 [==============================] - 0s 68us/step - loss: 0.5390 - mean_squared_error: 0.2100 - val_loss: 0.5616 - val_mean_squared_error: 0.2354\n",
      "Epoch 41/150\n",
      "5839/5839 [==============================] - 0s 69us/step - loss: 0.5355 - mean_squared_error: 0.2099 - val_loss: 0.5606 - val_mean_squared_error: 0.2357\n",
      "Epoch 42/150\n",
      "5839/5839 [==============================] - 0s 69us/step - loss: 0.5341 - mean_squared_error: 0.2106 - val_loss: 0.5563 - val_mean_squared_error: 0.2349\n",
      "Epoch 43/150\n",
      "5839/5839 [==============================] - 0s 69us/step - loss: 0.5280 - mean_squared_error: 0.2089 - val_loss: 0.5597 - val_mean_squared_error: 0.2395\n",
      "Epoch 44/150\n",
      "5839/5839 [==============================] - 0s 69us/step - loss: 0.5278 - mean_squared_error: 0.2086 - val_loss: 0.5522 - val_mean_squared_error: 0.2357\n",
      "Epoch 45/150\n",
      "5839/5839 [==============================] - 0s 72us/step - loss: 0.5239 - mean_squared_error: 0.2086 - val_loss: 0.5503 - val_mean_squared_error: 0.2368\n",
      "Epoch 46/150\n",
      "5839/5839 [==============================] - 0s 71us/step - loss: 0.5239 - mean_squared_error: 0.2093 - val_loss: 0.5479 - val_mean_squared_error: 0.2357\n",
      "Epoch 47/150\n",
      "5839/5839 [==============================] - 0s 77us/step - loss: 0.5197 - mean_squared_error: 0.2073 - val_loss: 0.5472 - val_mean_squared_error: 0.2376\n",
      "Epoch 48/150\n",
      "5839/5839 [==============================] - 1s 88us/step - loss: 0.5175 - mean_squared_error: 0.2080 - val_loss: 0.5462 - val_mean_squared_error: 0.2372\n",
      "Epoch 49/150\n",
      "5839/5839 [==============================] - 1s 90us/step - loss: 0.5162 - mean_squared_error: 0.2077 - val_loss: 0.5447 - val_mean_squared_error: 0.2376\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/150\n",
      "5839/5839 [==============================] - 0s 81us/step - loss: 0.5124 - mean_squared_error: 0.2058 - val_loss: 0.5409 - val_mean_squared_error: 0.2351\n",
      "Epoch 51/150\n",
      "5839/5839 [==============================] - 0s 78us/step - loss: 0.5124 - mean_squared_error: 0.2076 - val_loss: 0.5385 - val_mean_squared_error: 0.2346\n",
      "Epoch 52/150\n",
      "5839/5839 [==============================] - 1s 94us/step - loss: 0.5110 - mean_squared_error: 0.2065 - val_loss: 0.5442 - val_mean_squared_error: 0.2369\n",
      "Epoch 53/150\n",
      "5839/5839 [==============================] - 0s 73us/step - loss: 0.5094 - mean_squared_error: 0.2059 - val_loss: 0.5419 - val_mean_squared_error: 0.2388\n",
      "Epoch 54/150\n",
      "5839/5839 [==============================] - 0s 81us/step - loss: 0.5119 - mean_squared_error: 0.2077 - val_loss: 0.5441 - val_mean_squared_error: 0.2381\n",
      "Epoch 55/150\n",
      "5839/5839 [==============================] - 1s 96us/step - loss: 0.5102 - mean_squared_error: 0.2064 - val_loss: 0.5374 - val_mean_squared_error: 0.2347\n",
      "Epoch 56/150\n",
      "5839/5839 [==============================] - 0s 74us/step - loss: 0.5086 - mean_squared_error: 0.2064 - val_loss: 0.5381 - val_mean_squared_error: 0.2353\n",
      "Epoch 57/150\n",
      "5839/5839 [==============================] - 1s 92us/step - loss: 0.5105 - mean_squared_error: 0.2069 - val_loss: 0.5398 - val_mean_squared_error: 0.2361\n",
      "Epoch 58/150\n",
      "5839/5839 [==============================] - 0s 76us/step - loss: 0.5078 - mean_squared_error: 0.2057 - val_loss: 0.5319 - val_mean_squared_error: 0.2335\n",
      "Epoch 59/150\n",
      "5839/5839 [==============================] - 0s 76us/step - loss: 0.5044 - mean_squared_error: 0.2054 - val_loss: 0.5347 - val_mean_squared_error: 0.2358\n",
      "Epoch 60/150\n",
      "5839/5839 [==============================] - 0s 78us/step - loss: 0.5056 - mean_squared_error: 0.2064 - val_loss: 0.5353 - val_mean_squared_error: 0.2342\n",
      "Epoch 61/150\n",
      "5839/5839 [==============================] - 0s 83us/step - loss: 0.5038 - mean_squared_error: 0.2046 - val_loss: 0.5371 - val_mean_squared_error: 0.2387\n",
      "Epoch 62/150\n",
      "5839/5839 [==============================] - 0s 78us/step - loss: 0.5026 - mean_squared_error: 0.2053 - val_loss: 0.5328 - val_mean_squared_error: 0.2381\n",
      "Epoch 63/150\n",
      "5839/5839 [==============================] - 0s 80us/step - loss: 0.5026 - mean_squared_error: 0.2058 - val_loss: 0.5373 - val_mean_squared_error: 0.2419\n",
      "Epoch 64/150\n",
      "5839/5839 [==============================] - 0s 80us/step - loss: 0.5019 - mean_squared_error: 0.2055 - val_loss: 0.5310 - val_mean_squared_error: 0.2361\n",
      "Epoch 65/150\n",
      "5839/5839 [==============================] - 0s 77us/step - loss: 0.5023 - mean_squared_error: 0.2056 - val_loss: 0.5302 - val_mean_squared_error: 0.2345\n",
      "Epoch 66/150\n",
      "5839/5839 [==============================] - 0s 78us/step - loss: 0.5013 - mean_squared_error: 0.2050 - val_loss: 0.5291 - val_mean_squared_error: 0.2344\n",
      "Epoch 67/150\n",
      "5839/5839 [==============================] - 0s 77us/step - loss: 0.4993 - mean_squared_error: 0.2054 - val_loss: 0.5304 - val_mean_squared_error: 0.2346\n",
      "Epoch 68/150\n",
      "5839/5839 [==============================] - 0s 79us/step - loss: 0.5007 - mean_squared_error: 0.2051 - val_loss: 0.5298 - val_mean_squared_error: 0.2342\n",
      "Epoch 69/150\n",
      "5839/5839 [==============================] - 1s 86us/step - loss: 0.5017 - mean_squared_error: 0.2045 - val_loss: 0.5286 - val_mean_squared_error: 0.2343\n",
      "Epoch 70/150\n",
      "5839/5839 [==============================] - 0s 79us/step - loss: 0.5012 - mean_squared_error: 0.2066 - val_loss: 0.5308 - val_mean_squared_error: 0.2361\n",
      "Epoch 71/150\n",
      "5839/5839 [==============================] - 1s 96us/step - loss: 0.4992 - mean_squared_error: 0.2038 - val_loss: 0.5304 - val_mean_squared_error: 0.2360\n",
      "Epoch 72/150\n",
      "5839/5839 [==============================] - 1s 104us/step - loss: 0.4985 - mean_squared_error: 0.2050 - val_loss: 0.5292 - val_mean_squared_error: 0.2366\n",
      "Epoch 73/150\n",
      "5839/5839 [==============================] - 0s 76us/step - loss: 0.4970 - mean_squared_error: 0.2044 - val_loss: 0.5266 - val_mean_squared_error: 0.2335\n",
      "Epoch 74/150\n",
      "5839/5839 [==============================] - 1s 103us/step - loss: 0.4964 - mean_squared_error: 0.2033 - val_loss: 0.5312 - val_mean_squared_error: 0.2380\n",
      "Epoch 75/150\n",
      "5839/5839 [==============================] - 1s 90us/step - loss: 0.4988 - mean_squared_error: 0.2047 - val_loss: 0.5298 - val_mean_squared_error: 0.2354\n",
      "Epoch 76/150\n",
      "5839/5839 [==============================] - 1s 95us/step - loss: 0.5000 - mean_squared_error: 0.2042 - val_loss: 0.5305 - val_mean_squared_error: 0.2363\n",
      "Epoch 77/150\n",
      "5839/5839 [==============================] - 1s 98us/step - loss: 0.4968 - mean_squared_error: 0.2039 - val_loss: 0.5291 - val_mean_squared_error: 0.2370\n",
      "Epoch 78/150\n",
      "5839/5839 [==============================] - 0s 78us/step - loss: 0.4942 - mean_squared_error: 0.2030 - val_loss: 0.5244 - val_mean_squared_error: 0.2353\n",
      "Epoch 79/150\n",
      "5839/5839 [==============================] - 1s 96us/step - loss: 0.4943 - mean_squared_error: 0.2035 - val_loss: 0.5260 - val_mean_squared_error: 0.2361\n",
      "Epoch 80/150\n",
      "5839/5839 [==============================] - 1s 89us/step - loss: 0.4935 - mean_squared_error: 0.2029 - val_loss: 0.5269 - val_mean_squared_error: 0.2348\n",
      "Epoch 81/150\n",
      "5839/5839 [==============================] - 0s 78us/step - loss: 0.4938 - mean_squared_error: 0.2031 - val_loss: 0.5254 - val_mean_squared_error: 0.2366\n",
      "Epoch 82/150\n",
      "5839/5839 [==============================] - 0s 85us/step - loss: 0.4941 - mean_squared_error: 0.2041 - val_loss: 0.5302 - val_mean_squared_error: 0.2368\n",
      "Epoch 83/150\n",
      "5839/5839 [==============================] - 0s 77us/step - loss: 0.4947 - mean_squared_error: 0.2034 - val_loss: 0.5246 - val_mean_squared_error: 0.2343\n",
      "Epoch 84/150\n",
      "5839/5839 [==============================] - 0s 77us/step - loss: 0.4943 - mean_squared_error: 0.2034 - val_loss: 0.5239 - val_mean_squared_error: 0.2358\n",
      "Epoch 85/150\n",
      "5839/5839 [==============================] - 0s 74us/step - loss: 0.4926 - mean_squared_error: 0.2027 - val_loss: 0.5232 - val_mean_squared_error: 0.2326\n",
      "Epoch 86/150\n",
      "5839/5839 [==============================] - 0s 74us/step - loss: 0.4908 - mean_squared_error: 0.2026 - val_loss: 0.5247 - val_mean_squared_error: 0.2363\n",
      "Epoch 87/150\n",
      "5839/5839 [==============================] - 0s 74us/step - loss: 0.4908 - mean_squared_error: 0.2026 - val_loss: 0.5213 - val_mean_squared_error: 0.2339\n",
      "Epoch 88/150\n",
      "5839/5839 [==============================] - 0s 75us/step - loss: 0.4895 - mean_squared_error: 0.2022 - val_loss: 0.5207 - val_mean_squared_error: 0.2351\n",
      "Epoch 89/150\n",
      "5839/5839 [==============================] - 0s 76us/step - loss: 0.4921 - mean_squared_error: 0.2035 - val_loss: 0.5254 - val_mean_squared_error: 0.2365\n",
      "Epoch 90/150\n",
      "5839/5839 [==============================] - 0s 74us/step - loss: 0.4928 - mean_squared_error: 0.2030 - val_loss: 0.5218 - val_mean_squared_error: 0.2342\n",
      "Epoch 91/150\n",
      "5839/5839 [==============================] - 0s 73us/step - loss: 0.4915 - mean_squared_error: 0.2034 - val_loss: 0.5223 - val_mean_squared_error: 0.2348\n",
      "Epoch 92/150\n",
      "5839/5839 [==============================] - 0s 71us/step - loss: 0.4907 - mean_squared_error: 0.2023 - val_loss: 0.5256 - val_mean_squared_error: 0.2373\n",
      "Epoch 93/150\n",
      "5839/5839 [==============================] - 0s 82us/step - loss: 0.4923 - mean_squared_error: 0.2032 - val_loss: 0.5259 - val_mean_squared_error: 0.2366\n",
      "Epoch 94/150\n",
      "5839/5839 [==============================] - 0s 77us/step - loss: 0.4911 - mean_squared_error: 0.2025 - val_loss: 0.5233 - val_mean_squared_error: 0.2359\n",
      "Epoch 95/150\n",
      "5839/5839 [==============================] - 0s 82us/step - loss: 0.4890 - mean_squared_error: 0.2020 - val_loss: 0.5205 - val_mean_squared_error: 0.2336\n",
      "Epoch 96/150\n",
      "5839/5839 [==============================] - 0s 71us/step - loss: 0.4906 - mean_squared_error: 0.2029 - val_loss: 0.5221 - val_mean_squared_error: 0.2349\n",
      "Epoch 97/150\n",
      "5839/5839 [==============================] - 0s 73us/step - loss: 0.4914 - mean_squared_error: 0.2034 - val_loss: 0.5275 - val_mean_squared_error: 0.2391\n",
      "Epoch 98/150\n",
      "5839/5839 [==============================] - 0s 76us/step - loss: 0.4897 - mean_squared_error: 0.2022 - val_loss: 0.5223 - val_mean_squared_error: 0.2341\n",
      "Epoch 99/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5839/5839 [==============================] - 0s 67us/step - loss: 0.4923 - mean_squared_error: 0.2025 - val_loss: 0.5241 - val_mean_squared_error: 0.2358\n",
      "Epoch 100/150\n",
      "5839/5839 [==============================] - 0s 65us/step - loss: 0.4909 - mean_squared_error: 0.2018 - val_loss: 0.5230 - val_mean_squared_error: 0.2350\n",
      "Epoch 101/150\n",
      "5839/5839 [==============================] - 0s 63us/step - loss: 0.4889 - mean_squared_error: 0.2019 - val_loss: 0.5198 - val_mean_squared_error: 0.2336\n",
      "Epoch 102/150\n",
      "5839/5839 [==============================] - 0s 64us/step - loss: 0.4904 - mean_squared_error: 0.2016 - val_loss: 0.5229 - val_mean_squared_error: 0.2343\n",
      "Epoch 103/150\n",
      "5839/5839 [==============================] - 0s 68us/step - loss: 0.4889 - mean_squared_error: 0.2024 - val_loss: 0.5230 - val_mean_squared_error: 0.2371\n",
      "Epoch 104/150\n",
      "5839/5839 [==============================] - 0s 70us/step - loss: 0.4887 - mean_squared_error: 0.2023 - val_loss: 0.5220 - val_mean_squared_error: 0.2339\n",
      "Epoch 105/150\n",
      "5839/5839 [==============================] - 0s 68us/step - loss: 0.4890 - mean_squared_error: 0.2014 - val_loss: 0.5202 - val_mean_squared_error: 0.2336\n",
      "Epoch 106/150\n",
      "5839/5839 [==============================] - 0s 67us/step - loss: 0.4903 - mean_squared_error: 0.2014 - val_loss: 0.5256 - val_mean_squared_error: 0.2367\n",
      "Epoch 107/150\n",
      "5839/5839 [==============================] - 0s 71us/step - loss: 0.4896 - mean_squared_error: 0.2016 - val_loss: 0.5246 - val_mean_squared_error: 0.2375\n",
      "Epoch 108/150\n",
      "5839/5839 [==============================] - 0s 69us/step - loss: 0.4905 - mean_squared_error: 0.2029 - val_loss: 0.5216 - val_mean_squared_error: 0.2350\n",
      "Epoch 109/150\n",
      "5839/5839 [==============================] - 0s 68us/step - loss: 0.4878 - mean_squared_error: 0.2020 - val_loss: 0.5206 - val_mean_squared_error: 0.2350\n",
      "Epoch 110/150\n",
      "5839/5839 [==============================] - 0s 70us/step - loss: 0.4904 - mean_squared_error: 0.2022 - val_loss: 0.5183 - val_mean_squared_error: 0.2314\n",
      "Epoch 111/150\n",
      "5839/5839 [==============================] - 0s 71us/step - loss: 0.4892 - mean_squared_error: 0.2016 - val_loss: 0.5220 - val_mean_squared_error: 0.2334\n",
      "Epoch 112/150\n",
      "5839/5839 [==============================] - 0s 71us/step - loss: 0.4901 - mean_squared_error: 0.2018 - val_loss: 0.5245 - val_mean_squared_error: 0.2360\n",
      "Epoch 113/150\n",
      "5839/5839 [==============================] - 0s 66us/step - loss: 0.4900 - mean_squared_error: 0.2026 - val_loss: 0.5202 - val_mean_squared_error: 0.2331\n",
      "Epoch 114/150\n",
      "5839/5839 [==============================] - 0s 69us/step - loss: 0.4893 - mean_squared_error: 0.2020 - val_loss: 0.5225 - val_mean_squared_error: 0.2347\n",
      "Epoch 115/150\n",
      "5839/5839 [==============================] - 0s 68us/step - loss: 0.4897 - mean_squared_error: 0.2016 - val_loss: 0.5204 - val_mean_squared_error: 0.2328\n",
      "Epoch 116/150\n",
      "5839/5839 [==============================] - 0s 69us/step - loss: 0.4873 - mean_squared_error: 0.2010 - val_loss: 0.5167 - val_mean_squared_error: 0.2312\n",
      "Epoch 117/150\n",
      "5839/5839 [==============================] - 0s 71us/step - loss: 0.4871 - mean_squared_error: 0.2022 - val_loss: 0.5180 - val_mean_squared_error: 0.2323\n",
      "Epoch 118/150\n",
      "5839/5839 [==============================] - 0s 71us/step - loss: 0.4900 - mean_squared_error: 0.2013 - val_loss: 0.5256 - val_mean_squared_error: 0.2349\n",
      "Epoch 119/150\n",
      "5839/5839 [==============================] - 0s 71us/step - loss: 0.4873 - mean_squared_error: 0.2000 - val_loss: 0.5170 - val_mean_squared_error: 0.2314\n",
      "Epoch 120/150\n",
      "5839/5839 [==============================] - 0s 73us/step - loss: 0.4879 - mean_squared_error: 0.2015 - val_loss: 0.5187 - val_mean_squared_error: 0.2327\n",
      "Epoch 121/150\n",
      "5839/5839 [==============================] - 0s 76us/step - loss: 0.4881 - mean_squared_error: 0.2012 - val_loss: 0.5188 - val_mean_squared_error: 0.2307\n",
      "Epoch 122/150\n",
      "5839/5839 [==============================] - 0s 83us/step - loss: 0.4880 - mean_squared_error: 0.2005 - val_loss: 0.5232 - val_mean_squared_error: 0.2342\n",
      "Epoch 123/150\n",
      "5839/5839 [==============================] - 0s 79us/step - loss: 0.4869 - mean_squared_error: 0.1998 - val_loss: 0.5158 - val_mean_squared_error: 0.2321\n",
      "Epoch 124/150\n",
      "5839/5839 [==============================] - 1s 100us/step - loss: 0.4858 - mean_squared_error: 0.2009 - val_loss: 0.5163 - val_mean_squared_error: 0.2322\n",
      "Epoch 125/150\n",
      "5839/5839 [==============================] - 0s 81us/step - loss: 0.4851 - mean_squared_error: 0.2000 - val_loss: 0.5158 - val_mean_squared_error: 0.2310\n",
      "Epoch 126/150\n",
      "5839/5839 [==============================] - 0s 85us/step - loss: 0.4884 - mean_squared_error: 0.2012 - val_loss: 0.5219 - val_mean_squared_error: 0.2352\n",
      "Epoch 127/150\n",
      "5839/5839 [==============================] - 0s 83us/step - loss: 0.4870 - mean_squared_error: 0.2005 - val_loss: 0.5184 - val_mean_squared_error: 0.2318\n",
      "Epoch 128/150\n",
      "5839/5839 [==============================] - 0s 84us/step - loss: 0.4857 - mean_squared_error: 0.1995 - val_loss: 0.5200 - val_mean_squared_error: 0.2334\n",
      "Epoch 129/150\n",
      "5839/5839 [==============================] - 0s 79us/step - loss: 0.4851 - mean_squared_error: 0.1995 - val_loss: 0.5176 - val_mean_squared_error: 0.2325\n",
      "Epoch 130/150\n",
      "5839/5839 [==============================] - 0s 79us/step - loss: 0.4857 - mean_squared_error: 0.1999 - val_loss: 0.5205 - val_mean_squared_error: 0.2327\n",
      "Epoch 131/150\n",
      "5839/5839 [==============================] - 0s 74us/step - loss: 0.4871 - mean_squared_error: 0.1996 - val_loss: 0.5175 - val_mean_squared_error: 0.2310\n",
      "Epoch 132/150\n",
      "5839/5839 [==============================] - 0s 77us/step - loss: 0.4868 - mean_squared_error: 0.1993 - val_loss: 0.5178 - val_mean_squared_error: 0.2313\n",
      "Epoch 133/150\n",
      "5839/5839 [==============================] - 0s 76us/step - loss: 0.4871 - mean_squared_error: 0.2002 - val_loss: 0.5142 - val_mean_squared_error: 0.2308\n",
      "Epoch 134/150\n",
      "5839/5839 [==============================] - 1s 87us/step - loss: 0.4831 - mean_squared_error: 0.1990 - val_loss: 0.5160 - val_mean_squared_error: 0.2307\n",
      "Epoch 135/150\n",
      "5839/5839 [==============================] - 0s 73us/step - loss: 0.4855 - mean_squared_error: 0.1985 - val_loss: 0.5174 - val_mean_squared_error: 0.2300\n",
      "Epoch 136/150\n",
      "5839/5839 [==============================] - 0s 77us/step - loss: 0.4870 - mean_squared_error: 0.2005 - val_loss: 0.5204 - val_mean_squared_error: 0.2341\n",
      "Epoch 137/150\n",
      "5839/5839 [==============================] - 0s 82us/step - loss: 0.4870 - mean_squared_error: 0.2001 - val_loss: 0.5190 - val_mean_squared_error: 0.2327\n",
      "Epoch 138/150\n",
      "5839/5839 [==============================] - 1s 102us/step - loss: 0.4851 - mean_squared_error: 0.1995 - val_loss: 0.5178 - val_mean_squared_error: 0.2326\n",
      "Epoch 139/150\n",
      "5839/5839 [==============================] - 1s 88us/step - loss: 0.4846 - mean_squared_error: 0.1991 - val_loss: 0.5167 - val_mean_squared_error: 0.2287\n",
      "Epoch 140/150\n",
      "5839/5839 [==============================] - 1s 112us/step - loss: 0.4861 - mean_squared_error: 0.1994 - val_loss: 0.5226 - val_mean_squared_error: 0.2354\n",
      "Epoch 141/150\n",
      "5839/5839 [==============================] - 1s 101us/step - loss: 0.4842 - mean_squared_error: 0.1985 - val_loss: 0.5137 - val_mean_squared_error: 0.2281\n",
      "Epoch 142/150\n",
      "5839/5839 [==============================] - 1s 107us/step - loss: 0.4833 - mean_squared_error: 0.1986 - val_loss: 0.5135 - val_mean_squared_error: 0.2291\n",
      "Epoch 143/150\n",
      "5839/5839 [==============================] - 1s 97us/step - loss: 0.4838 - mean_squared_error: 0.1986 - val_loss: 0.5176 - val_mean_squared_error: 0.2322\n",
      "Epoch 144/150\n",
      "5839/5839 [==============================] - 0s 85us/step - loss: 0.4840 - mean_squared_error: 0.1987 - val_loss: 0.5155 - val_mean_squared_error: 0.2303\n",
      "Epoch 145/150\n",
      "5839/5839 [==============================] - 0s 80us/step - loss: 0.4849 - mean_squared_error: 0.1986 - val_loss: 0.5167 - val_mean_squared_error: 0.2313\n",
      "Epoch 146/150\n",
      "5839/5839 [==============================] - 0s 82us/step - loss: 0.4838 - mean_squared_error: 0.1986 - val_loss: 0.5167 - val_mean_squared_error: 0.2294\n",
      "Epoch 147/150\n",
      "5839/5839 [==============================] - 0s 75us/step - loss: 0.4868 - mean_squared_error: 0.1994 - val_loss: 0.5181 - val_mean_squared_error: 0.2314\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 148/150\n",
      "5839/5839 [==============================] - 0s 67us/step - loss: 0.4842 - mean_squared_error: 0.1984 - val_loss: 0.5151 - val_mean_squared_error: 0.2300\n",
      "Epoch 149/150\n",
      "5839/5839 [==============================] - 0s 65us/step - loss: 0.4840 - mean_squared_error: 0.1985 - val_loss: 0.5159 - val_mean_squared_error: 0.2299\n",
      "Epoch 150/150\n",
      "5839/5839 [==============================] - 0s 64us/step - loss: 0.4842 - mean_squared_error: 0.1990 - val_loss: 0.5139 - val_mean_squared_error: 0.2281\n",
      "Training MSE: 0.1965\n",
      "Validation MSE: 0.1669\n",
      "\n",
      "Training r2: 0.6352\n",
      "Validation r2: 0.6663\n"
     ]
    }
   ],
   "source": [
    "nn4 = models.Sequential()\n",
    "nn4.add(layers.Dense(128, input_shape=(X_train.shape[1],), kernel_regularizer=regularizers.l1(0.01), activation='relu'))\n",
    "nn4.add(layers.Dense(256, kernel_regularizer=regularizers.l1(0.01), activation='relu'))\n",
    "nn4.add(layers.Dense(512, kernel_regularizer=regularizers.l1(0.01), activation='relu'))\n",
    "nn4.add(layers.Dense(1, activation='relu'))\n",
    "\n",
    "# Compiling the model\n",
    "nn4.compile(loss='mean_squared_error',\n",
    "            optimizer='adam',\n",
    "            metrics=['mean_squared_error'])\n",
    "\n",
    "nn4_history = nn4.fit(X_train,\n",
    "                  y_train,\n",
    "                  epochs=150,\n",
    "                  batch_size=256,\n",
    "                  validation_split = 0.1)\n",
    "\n",
    "nn_model_evaluation(nn4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "still-swedish",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5839 samples, validate on 649 samples\n",
      "Epoch 1/150\n",
      "5839/5839 [==============================] - 1s 142us/step - loss: 180.8595 - mean_squared_error: 8.9929 - val_loss: 147.5954 - val_mean_squared_error: 4.2708\n",
      "Epoch 2/150\n",
      "5839/5839 [==============================] - 0s 69us/step - loss: 122.2835 - mean_squared_error: 2.5069 - val_loss: 96.7747 - val_mean_squared_error: 1.4299\n",
      "Epoch 3/150\n",
      "5839/5839 [==============================] - 0s 68us/step - loss: 77.6673 - mean_squared_error: 0.9363 - val_loss: 59.0357 - val_mean_squared_error: 0.7073\n",
      "Epoch 4/150\n",
      "5839/5839 [==============================] - 0s 73us/step - loss: 46.6240 - mean_squared_error: 0.5052 - val_loss: 35.5319 - val_mean_squared_error: 0.4985\n",
      "Epoch 5/150\n",
      "5839/5839 [==============================] - 0s 69us/step - loss: 28.4357 - mean_squared_error: 0.3877 - val_loss: 22.0652 - val_mean_squared_error: 0.4351\n",
      "Epoch 6/150\n",
      "5839/5839 [==============================] - 0s 70us/step - loss: 18.0025 - mean_squared_error: 0.3280 - val_loss: 14.3784 - val_mean_squared_error: 0.3582\n",
      "Epoch 7/150\n",
      "5839/5839 [==============================] - 0s 70us/step - loss: 11.9276 - mean_squared_error: 0.2889 - val_loss: 9.7042 - val_mean_squared_error: 0.3216\n",
      "Epoch 8/150\n",
      "5839/5839 [==============================] - 0s 70us/step - loss: 8.1449 - mean_squared_error: 0.2749 - val_loss: 6.7477 - val_mean_squared_error: 0.3174\n",
      "Epoch 9/150\n",
      "5839/5839 [==============================] - 0s 70us/step - loss: 5.7342 - mean_squared_error: 0.2855 - val_loss: 4.8430 - val_mean_squared_error: 0.3308\n",
      "Epoch 10/150\n",
      "5839/5839 [==============================] - 0s 69us/step - loss: 4.1682 - mean_squared_error: 0.3020 - val_loss: 3.5925 - val_mean_squared_error: 0.3490\n",
      "Epoch 11/150\n",
      "5839/5839 [==============================] - 0s 82us/step - loss: 3.1355 - mean_squared_error: 0.3167 - val_loss: 2.7652 - val_mean_squared_error: 0.3596\n",
      "Epoch 12/150\n",
      "5839/5839 [==============================] - 0s 70us/step - loss: 2.4497 - mean_squared_error: 0.3248 - val_loss: 2.2203 - val_mean_squared_error: 0.3652\n",
      "Epoch 13/150\n",
      "5839/5839 [==============================] - 0s 75us/step - loss: 1.9926 - mean_squared_error: 0.3286 - val_loss: 1.8525 - val_mean_squared_error: 0.3645\n",
      "Epoch 14/150\n",
      "5839/5839 [==============================] - 0s 73us/step - loss: 1.6862 - mean_squared_error: 0.3285 - val_loss: 1.6007 - val_mean_squared_error: 0.3654\n",
      "Epoch 15/150\n",
      "5839/5839 [==============================] - 0s 71us/step - loss: 1.4785 - mean_squared_error: 0.3228 - val_loss: 1.4363 - val_mean_squared_error: 0.3607\n",
      "Epoch 16/150\n",
      "5839/5839 [==============================] - 0s 79us/step - loss: 1.3269 - mean_squared_error: 0.3171 - val_loss: 1.3054 - val_mean_squared_error: 0.3542\n",
      "Epoch 17/150\n",
      "5839/5839 [==============================] - 0s 75us/step - loss: 1.2221 - mean_squared_error: 0.3095 - val_loss: 1.2161 - val_mean_squared_error: 0.3448\n",
      "Epoch 18/150\n",
      "5839/5839 [==============================] - 0s 75us/step - loss: 1.1388 - mean_squared_error: 0.3035 - val_loss: 1.1437 - val_mean_squared_error: 0.3416\n",
      "Epoch 19/150\n",
      "5839/5839 [==============================] - 0s 71us/step - loss: 1.0708 - mean_squared_error: 0.2943 - val_loss: 1.0838 - val_mean_squared_error: 0.3307\n",
      "Epoch 20/150\n",
      "5839/5839 [==============================] - 0s 71us/step - loss: 1.0210 - mean_squared_error: 0.2860 - val_loss: 1.0350 - val_mean_squared_error: 0.3224\n",
      "Epoch 21/150\n",
      "5839/5839 [==============================] - 0s 71us/step - loss: 0.9837 - mean_squared_error: 0.2786 - val_loss: 1.0045 - val_mean_squared_error: 0.3125\n",
      "Epoch 22/150\n",
      "5839/5839 [==============================] - 0s 71us/step - loss: 0.9512 - mean_squared_error: 0.2713 - val_loss: 0.9750 - val_mean_squared_error: 0.3077\n",
      "Epoch 23/150\n",
      "5839/5839 [==============================] - 0s 71us/step - loss: 0.9229 - mean_squared_error: 0.2644 - val_loss: 0.9504 - val_mean_squared_error: 0.3000\n",
      "Epoch 24/150\n",
      "5839/5839 [==============================] - 0s 69us/step - loss: 0.9024 - mean_squared_error: 0.2579 - val_loss: 0.9274 - val_mean_squared_error: 0.2929\n",
      "Epoch 25/150\n",
      "5839/5839 [==============================] - 0s 72us/step - loss: 0.8888 - mean_squared_error: 0.2532 - val_loss: 0.9184 - val_mean_squared_error: 0.2846\n",
      "Epoch 26/150\n",
      "5839/5839 [==============================] - 0s 72us/step - loss: 0.8761 - mean_squared_error: 0.2464 - val_loss: 0.9015 - val_mean_squared_error: 0.2806\n",
      "Epoch 27/150\n",
      "5839/5839 [==============================] - 0s 72us/step - loss: 0.8592 - mean_squared_error: 0.2430 - val_loss: 0.8935 - val_mean_squared_error: 0.2775\n",
      "Epoch 28/150\n",
      "5839/5839 [==============================] - 0s 73us/step - loss: 0.8535 - mean_squared_error: 0.2397 - val_loss: 0.8754 - val_mean_squared_error: 0.2696\n",
      "Epoch 29/150\n",
      "5839/5839 [==============================] - 0s 70us/step - loss: 0.8465 - mean_squared_error: 0.2358 - val_loss: 0.8802 - val_mean_squared_error: 0.2731\n",
      "Epoch 30/150\n",
      "5839/5839 [==============================] - 0s 76us/step - loss: 0.8441 - mean_squared_error: 0.2346 - val_loss: 0.8692 - val_mean_squared_error: 0.2630\n",
      "Epoch 31/150\n",
      "5839/5839 [==============================] - 0s 72us/step - loss: 0.8294 - mean_squared_error: 0.2318 - val_loss: 0.8608 - val_mean_squared_error: 0.2634\n",
      "Epoch 32/150\n",
      "5839/5839 [==============================] - 0s 76us/step - loss: 0.8242 - mean_squared_error: 0.2307 - val_loss: 0.8497 - val_mean_squared_error: 0.2579\n",
      "Epoch 33/150\n",
      "5839/5839 [==============================] - 0s 77us/step - loss: 0.8217 - mean_squared_error: 0.2289 - val_loss: 0.8454 - val_mean_squared_error: 0.2572\n",
      "Epoch 34/150\n",
      "5839/5839 [==============================] - 0s 72us/step - loss: 0.8189 - mean_squared_error: 0.2275 - val_loss: 0.8461 - val_mean_squared_error: 0.2554\n",
      "Epoch 35/150\n",
      "5839/5839 [==============================] - 0s 76us/step - loss: 0.8185 - mean_squared_error: 0.2274 - val_loss: 0.8463 - val_mean_squared_error: 0.2590\n",
      "Epoch 36/150\n",
      "5839/5839 [==============================] - 0s 77us/step - loss: 0.8131 - mean_squared_error: 0.2263 - val_loss: 0.8413 - val_mean_squared_error: 0.2525\n",
      "Epoch 37/150\n",
      "5839/5839 [==============================] - 0s 66us/step - loss: 0.8115 - mean_squared_error: 0.2248 - val_loss: 0.8400 - val_mean_squared_error: 0.2552\n",
      "Epoch 38/150\n",
      "5839/5839 [==============================] - 0s 68us/step - loss: 0.8036 - mean_squared_error: 0.2229 - val_loss: 0.8377 - val_mean_squared_error: 0.2552\n",
      "Epoch 39/150\n",
      "5839/5839 [==============================] - 0s 70us/step - loss: 0.8096 - mean_squared_error: 0.2242 - val_loss: 0.8450 - val_mean_squared_error: 0.2553\n",
      "Epoch 40/150\n",
      "5839/5839 [==============================] - 0s 69us/step - loss: 0.8078 - mean_squared_error: 0.2227 - val_loss: 0.8310 - val_mean_squared_error: 0.2525\n",
      "Epoch 41/150\n",
      "5839/5839 [==============================] - 0s 70us/step - loss: 0.8026 - mean_squared_error: 0.2237 - val_loss: 0.8312 - val_mean_squared_error: 0.2527\n",
      "Epoch 42/150\n",
      "5839/5839 [==============================] - 0s 71us/step - loss: 0.8001 - mean_squared_error: 0.2226 - val_loss: 0.8306 - val_mean_squared_error: 0.2520\n",
      "Epoch 43/150\n",
      "5839/5839 [==============================] - 0s 70us/step - loss: 0.7974 - mean_squared_error: 0.2217 - val_loss: 0.8303 - val_mean_squared_error: 0.2540\n",
      "Epoch 44/150\n",
      "5839/5839 [==============================] - 0s 69us/step - loss: 0.8000 - mean_squared_error: 0.2219 - val_loss: 0.8307 - val_mean_squared_error: 0.2520\n",
      "Epoch 45/150\n",
      "5839/5839 [==============================] - 0s 68us/step - loss: 0.7976 - mean_squared_error: 0.2195 - val_loss: 0.8319 - val_mean_squared_error: 0.2565\n",
      "Epoch 46/150\n",
      "5839/5839 [==============================] - 0s 68us/step - loss: 0.7955 - mean_squared_error: 0.2213 - val_loss: 0.8300 - val_mean_squared_error: 0.2523\n",
      "Epoch 47/150\n",
      "5839/5839 [==============================] - 0s 67us/step - loss: 0.7954 - mean_squared_error: 0.2204 - val_loss: 0.8214 - val_mean_squared_error: 0.2503\n",
      "Epoch 48/150\n",
      "5839/5839 [==============================] - 0s 71us/step - loss: 0.7935 - mean_squared_error: 0.2195 - val_loss: 0.8223 - val_mean_squared_error: 0.2488\n",
      "Epoch 49/150\n",
      "5839/5839 [==============================] - 0s 68us/step - loss: 0.7949 - mean_squared_error: 0.2202 - val_loss: 0.8313 - val_mean_squared_error: 0.2491\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/150\n",
      "5839/5839 [==============================] - 0s 62us/step - loss: 0.7957 - mean_squared_error: 0.2193 - val_loss: 0.8220 - val_mean_squared_error: 0.2506\n",
      "Epoch 51/150\n",
      "5839/5839 [==============================] - 0s 60us/step - loss: 0.7904 - mean_squared_error: 0.2200 - val_loss: 0.8182 - val_mean_squared_error: 0.2495\n",
      "Epoch 52/150\n",
      "5839/5839 [==============================] - 0s 60us/step - loss: 0.7880 - mean_squared_error: 0.2186 - val_loss: 0.8174 - val_mean_squared_error: 0.2495\n",
      "Epoch 53/150\n",
      "5839/5839 [==============================] - 0s 63us/step - loss: 0.7876 - mean_squared_error: 0.2185 - val_loss: 0.8155 - val_mean_squared_error: 0.2461\n",
      "Epoch 54/150\n",
      "5839/5839 [==============================] - 0s 62us/step - loss: 0.7907 - mean_squared_error: 0.2190 - val_loss: 0.8184 - val_mean_squared_error: 0.2490\n",
      "Epoch 55/150\n",
      "5839/5839 [==============================] - 0s 62us/step - loss: 0.7867 - mean_squared_error: 0.2185 - val_loss: 0.8143 - val_mean_squared_error: 0.2486\n",
      "Epoch 56/150\n",
      "5839/5839 [==============================] - 0s 63us/step - loss: 0.7874 - mean_squared_error: 0.2174 - val_loss: 0.8191 - val_mean_squared_error: 0.2488\n",
      "Epoch 57/150\n",
      "5839/5839 [==============================] - 0s 63us/step - loss: 0.7859 - mean_squared_error: 0.2180 - val_loss: 0.8052 - val_mean_squared_error: 0.2443\n",
      "Epoch 58/150\n",
      "5839/5839 [==============================] - 0s 64us/step - loss: 0.7821 - mean_squared_error: 0.2175 - val_loss: 0.8081 - val_mean_squared_error: 0.2466\n",
      "Epoch 59/150\n",
      "5839/5839 [==============================] - 0s 66us/step - loss: 0.7787 - mean_squared_error: 0.2167 - val_loss: 0.8101 - val_mean_squared_error: 0.2471\n",
      "Epoch 60/150\n",
      "5839/5839 [==============================] - 0s 65us/step - loss: 0.7825 - mean_squared_error: 0.2175 - val_loss: 0.8187 - val_mean_squared_error: 0.2511\n",
      "Epoch 61/150\n",
      "5839/5839 [==============================] - 0s 65us/step - loss: 0.7859 - mean_squared_error: 0.2178 - val_loss: 0.8165 - val_mean_squared_error: 0.2493\n",
      "Epoch 62/150\n",
      "5839/5839 [==============================] - 0s 70us/step - loss: 0.7788 - mean_squared_error: 0.2165 - val_loss: 0.8059 - val_mean_squared_error: 0.2468\n",
      "Epoch 63/150\n",
      "5839/5839 [==============================] - 0s 67us/step - loss: 0.7789 - mean_squared_error: 0.2168 - val_loss: 0.8163 - val_mean_squared_error: 0.2448\n",
      "Epoch 64/150\n",
      "5839/5839 [==============================] - 0s 67us/step - loss: 0.7857 - mean_squared_error: 0.2169 - val_loss: 0.8100 - val_mean_squared_error: 0.2454\n",
      "Epoch 65/150\n",
      "5839/5839 [==============================] - 0s 67us/step - loss: 0.7785 - mean_squared_error: 0.2171 - val_loss: 0.8089 - val_mean_squared_error: 0.2474\n",
      "Epoch 66/150\n",
      "5839/5839 [==============================] - 0s 69us/step - loss: 0.7793 - mean_squared_error: 0.2173 - val_loss: 0.8092 - val_mean_squared_error: 0.2456\n",
      "Epoch 67/150\n",
      "5839/5839 [==============================] - 0s 65us/step - loss: 0.7765 - mean_squared_error: 0.2163 - val_loss: 0.8021 - val_mean_squared_error: 0.2433\n",
      "Epoch 68/150\n",
      "5839/5839 [==============================] - 0s 66us/step - loss: 0.7730 - mean_squared_error: 0.2166 - val_loss: 0.8054 - val_mean_squared_error: 0.2456\n",
      "Epoch 69/150\n",
      "5839/5839 [==============================] - 0s 67us/step - loss: 0.7746 - mean_squared_error: 0.2162 - val_loss: 0.7992 - val_mean_squared_error: 0.2442\n",
      "Epoch 70/150\n",
      "5839/5839 [==============================] - 0s 67us/step - loss: 0.7715 - mean_squared_error: 0.2153 - val_loss: 0.7999 - val_mean_squared_error: 0.2438\n",
      "Epoch 71/150\n",
      "5839/5839 [==============================] - 0s 66us/step - loss: 0.7706 - mean_squared_error: 0.2158 - val_loss: 0.7994 - val_mean_squared_error: 0.2444\n",
      "Epoch 72/150\n",
      "5839/5839 [==============================] - 0s 66us/step - loss: 0.7697 - mean_squared_error: 0.2157 - val_loss: 0.7993 - val_mean_squared_error: 0.2484\n",
      "Epoch 73/150\n",
      "5839/5839 [==============================] - 0s 69us/step - loss: 0.7688 - mean_squared_error: 0.2145 - val_loss: 0.7938 - val_mean_squared_error: 0.2438\n",
      "Epoch 74/150\n",
      "5839/5839 [==============================] - 0s 66us/step - loss: 0.7659 - mean_squared_error: 0.2154 - val_loss: 0.7950 - val_mean_squared_error: 0.2446\n",
      "Epoch 75/150\n",
      "5839/5839 [==============================] - 0s 68us/step - loss: 0.7674 - mean_squared_error: 0.2152 - val_loss: 0.7930 - val_mean_squared_error: 0.2454\n",
      "Epoch 76/150\n",
      "5839/5839 [==============================] - 0s 70us/step - loss: 0.7636 - mean_squared_error: 0.2148 - val_loss: 0.7947 - val_mean_squared_error: 0.2456\n",
      "Epoch 77/150\n",
      "5839/5839 [==============================] - 0s 67us/step - loss: 0.7643 - mean_squared_error: 0.2148 - val_loss: 0.7973 - val_mean_squared_error: 0.2483\n",
      "Epoch 78/150\n",
      "5839/5839 [==============================] - 0s 66us/step - loss: 0.7631 - mean_squared_error: 0.2152 - val_loss: 0.7964 - val_mean_squared_error: 0.2451\n",
      "Epoch 79/150\n",
      "5839/5839 [==============================] - 0s 69us/step - loss: 0.7618 - mean_squared_error: 0.2153 - val_loss: 0.7902 - val_mean_squared_error: 0.2464\n",
      "Epoch 80/150\n",
      "5839/5839 [==============================] - 0s 68us/step - loss: 0.7615 - mean_squared_error: 0.2151 - val_loss: 0.7917 - val_mean_squared_error: 0.2442\n",
      "Epoch 81/150\n",
      "5839/5839 [==============================] - 0s 80us/step - loss: 0.7614 - mean_squared_error: 0.2141 - val_loss: 0.7919 - val_mean_squared_error: 0.2450\n",
      "Epoch 82/150\n",
      "5839/5839 [==============================] - 0s 71us/step - loss: 0.7602 - mean_squared_error: 0.2144 - val_loss: 0.7865 - val_mean_squared_error: 0.2402\n",
      "Epoch 83/150\n",
      "5839/5839 [==============================] - 0s 66us/step - loss: 0.7628 - mean_squared_error: 0.2152 - val_loss: 0.7902 - val_mean_squared_error: 0.2435\n",
      "Epoch 84/150\n",
      "5839/5839 [==============================] - 0s 69us/step - loss: 0.7589 - mean_squared_error: 0.2142 - val_loss: 0.7886 - val_mean_squared_error: 0.2440\n",
      "Epoch 85/150\n",
      "5839/5839 [==============================] - 0s 67us/step - loss: 0.7585 - mean_squared_error: 0.2144 - val_loss: 0.7891 - val_mean_squared_error: 0.2428\n",
      "Epoch 86/150\n",
      "5839/5839 [==============================] - 0s 69us/step - loss: 0.7561 - mean_squared_error: 0.2132 - val_loss: 0.7848 - val_mean_squared_error: 0.2434\n",
      "Epoch 87/150\n",
      "5839/5839 [==============================] - 0s 69us/step - loss: 0.7571 - mean_squared_error: 0.2148 - val_loss: 0.7846 - val_mean_squared_error: 0.2435\n",
      "Epoch 88/150\n",
      "5839/5839 [==============================] - 0s 66us/step - loss: 0.7583 - mean_squared_error: 0.2147 - val_loss: 0.7856 - val_mean_squared_error: 0.2436\n",
      "Epoch 89/150\n",
      "5839/5839 [==============================] - 0s 70us/step - loss: 0.7571 - mean_squared_error: 0.2146 - val_loss: 0.7870 - val_mean_squared_error: 0.2459\n",
      "Epoch 90/150\n",
      "5839/5839 [==============================] - 0s 68us/step - loss: 0.7535 - mean_squared_error: 0.2136 - val_loss: 0.7780 - val_mean_squared_error: 0.2406\n",
      "Epoch 91/150\n",
      "5839/5839 [==============================] - 0s 69us/step - loss: 0.7544 - mean_squared_error: 0.2150 - val_loss: 0.7825 - val_mean_squared_error: 0.2433\n",
      "Epoch 92/150\n",
      "5839/5839 [==============================] - 0s 71us/step - loss: 0.7535 - mean_squared_error: 0.2145 - val_loss: 0.7829 - val_mean_squared_error: 0.2430\n",
      "Epoch 93/150\n",
      "5839/5839 [==============================] - 0s 71us/step - loss: 0.7545 - mean_squared_error: 0.2156 - val_loss: 0.7856 - val_mean_squared_error: 0.2456\n",
      "Epoch 94/150\n",
      "5839/5839 [==============================] - 0s 69us/step - loss: 0.7508 - mean_squared_error: 0.2132 - val_loss: 0.7780 - val_mean_squared_error: 0.2422\n",
      "Epoch 95/150\n",
      "5839/5839 [==============================] - 0s 67us/step - loss: 0.7533 - mean_squared_error: 0.2145 - val_loss: 0.7836 - val_mean_squared_error: 0.2423\n",
      "Epoch 96/150\n",
      "5839/5839 [==============================] - 0s 72us/step - loss: 0.7571 - mean_squared_error: 0.2145 - val_loss: 0.7855 - val_mean_squared_error: 0.2448\n",
      "Epoch 97/150\n",
      "5839/5839 [==============================] - 0s 76us/step - loss: 0.7535 - mean_squared_error: 0.2142 - val_loss: 0.7820 - val_mean_squared_error: 0.2439\n",
      "Epoch 98/150\n",
      "5839/5839 [==============================] - 0s 71us/step - loss: 0.7513 - mean_squared_error: 0.2138 - val_loss: 0.7791 - val_mean_squared_error: 0.2436\n",
      "Epoch 99/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5839/5839 [==============================] - 0s 67us/step - loss: 0.7509 - mean_squared_error: 0.2152 - val_loss: 0.7789 - val_mean_squared_error: 0.2433\n",
      "Epoch 100/150\n",
      "5839/5839 [==============================] - 0s 67us/step - loss: 0.7546 - mean_squared_error: 0.2149 - val_loss: 0.7831 - val_mean_squared_error: 0.2442\n",
      "Epoch 101/150\n",
      "5839/5839 [==============================] - 0s 67us/step - loss: 0.7525 - mean_squared_error: 0.2150 - val_loss: 0.7775 - val_mean_squared_error: 0.2413\n",
      "Epoch 102/150\n",
      "5839/5839 [==============================] - 0s 66us/step - loss: 0.7498 - mean_squared_error: 0.2141 - val_loss: 0.7863 - val_mean_squared_error: 0.2476\n",
      "Epoch 103/150\n",
      "5839/5839 [==============================] - 0s 68us/step - loss: 0.7553 - mean_squared_error: 0.2146 - val_loss: 0.7794 - val_mean_squared_error: 0.2447\n",
      "Epoch 104/150\n",
      "5839/5839 [==============================] - ETA: 0s - loss: 0.7485 - mean_squared_error: 0.21 - 0s 66us/step - loss: 0.7516 - mean_squared_error: 0.2146 - val_loss: 0.7809 - val_mean_squared_error: 0.2427\n",
      "Epoch 105/150\n",
      "5839/5839 [==============================] - 0s 67us/step - loss: 0.7497 - mean_squared_error: 0.2140 - val_loss: 0.7811 - val_mean_squared_error: 0.2429\n",
      "Epoch 106/150\n",
      "5839/5839 [==============================] - 0s 70us/step - loss: 0.7499 - mean_squared_error: 0.2146 - val_loss: 0.7785 - val_mean_squared_error: 0.2424\n",
      "Epoch 107/150\n",
      "5839/5839 [==============================] - 0s 65us/step - loss: 0.7509 - mean_squared_error: 0.2146 - val_loss: 0.7738 - val_mean_squared_error: 0.2427\n",
      "Epoch 108/150\n",
      "5839/5839 [==============================] - 0s 67us/step - loss: 0.7498 - mean_squared_error: 0.2155 - val_loss: 0.7783 - val_mean_squared_error: 0.2426\n",
      "Epoch 109/150\n",
      "5839/5839 [==============================] - 0s 67us/step - loss: 0.7532 - mean_squared_error: 0.2153 - val_loss: 0.7851 - val_mean_squared_error: 0.2460\n",
      "Epoch 110/150\n",
      "5839/5839 [==============================] - 0s 66us/step - loss: 0.7512 - mean_squared_error: 0.2140 - val_loss: 0.7803 - val_mean_squared_error: 0.2443\n",
      "Epoch 111/150\n",
      "5839/5839 [==============================] - 0s 66us/step - loss: 0.7483 - mean_squared_error: 0.2146 - val_loss: 0.7784 - val_mean_squared_error: 0.2439\n",
      "Epoch 112/150\n",
      "5839/5839 [==============================] - 0s 65us/step - loss: 0.7461 - mean_squared_error: 0.2140 - val_loss: 0.7755 - val_mean_squared_error: 0.2435\n",
      "Epoch 113/150\n",
      "5839/5839 [==============================] - 0s 66us/step - loss: 0.7468 - mean_squared_error: 0.2146 - val_loss: 0.7777 - val_mean_squared_error: 0.2430\n",
      "Epoch 114/150\n",
      "5839/5839 [==============================] - 0s 68us/step - loss: 0.7453 - mean_squared_error: 0.2147 - val_loss: 0.7715 - val_mean_squared_error: 0.2422\n",
      "Epoch 115/150\n",
      "5839/5839 [==============================] - 0s 68us/step - loss: 0.7458 - mean_squared_error: 0.2136 - val_loss: 0.7791 - val_mean_squared_error: 0.2444\n",
      "Epoch 116/150\n",
      "5839/5839 [==============================] - 0s 67us/step - loss: 0.7469 - mean_squared_error: 0.2148 - val_loss: 0.7743 - val_mean_squared_error: 0.2448\n",
      "Epoch 117/150\n",
      "5839/5839 [==============================] - 0s 70us/step - loss: 0.7488 - mean_squared_error: 0.2157 - val_loss: 0.7802 - val_mean_squared_error: 0.2462\n",
      "Epoch 118/150\n",
      "5839/5839 [==============================] - 0s 69us/step - loss: 0.7483 - mean_squared_error: 0.2141 - val_loss: 0.7754 - val_mean_squared_error: 0.2437\n",
      "Epoch 119/150\n",
      "5839/5839 [==============================] - 0s 68us/step - loss: 0.7466 - mean_squared_error: 0.2148 - val_loss: 0.7758 - val_mean_squared_error: 0.2434\n",
      "Epoch 120/150\n",
      "5839/5839 [==============================] - 0s 68us/step - loss: 0.7450 - mean_squared_error: 0.2141 - val_loss: 0.7732 - val_mean_squared_error: 0.2447\n",
      "Epoch 121/150\n",
      "5839/5839 [==============================] - 0s 69us/step - loss: 0.7471 - mean_squared_error: 0.2154 - val_loss: 0.7805 - val_mean_squared_error: 0.2454\n",
      "Epoch 122/150\n",
      "5839/5839 [==============================] - 0s 74us/step - loss: 0.7468 - mean_squared_error: 0.2158 - val_loss: 0.7788 - val_mean_squared_error: 0.2459\n",
      "Epoch 123/150\n",
      "5839/5839 [==============================] - 0s 65us/step - loss: 0.7447 - mean_squared_error: 0.2140 - val_loss: 0.7793 - val_mean_squared_error: 0.2473\n",
      "Epoch 124/150\n",
      "5839/5839 [==============================] - 0s 66us/step - loss: 0.7453 - mean_squared_error: 0.2141 - val_loss: 0.7798 - val_mean_squared_error: 0.2475\n",
      "Epoch 125/150\n",
      "5839/5839 [==============================] - 0s 67us/step - loss: 0.7462 - mean_squared_error: 0.2148 - val_loss: 0.7723 - val_mean_squared_error: 0.2431\n",
      "Epoch 126/150\n",
      "5839/5839 [==============================] - 0s 68us/step - loss: 0.7436 - mean_squared_error: 0.2138 - val_loss: 0.7719 - val_mean_squared_error: 0.2417\n",
      "Epoch 127/150\n",
      "5839/5839 [==============================] - 0s 69us/step - loss: 0.7452 - mean_squared_error: 0.2138 - val_loss: 0.7773 - val_mean_squared_error: 0.2461\n",
      "Epoch 128/150\n",
      "5839/5839 [==============================] - 0s 71us/step - loss: 0.7436 - mean_squared_error: 0.2142 - val_loss: 0.7719 - val_mean_squared_error: 0.2459\n",
      "Epoch 129/150\n",
      "5839/5839 [==============================] - 0s 72us/step - loss: 0.7409 - mean_squared_error: 0.2136 - val_loss: 0.7725 - val_mean_squared_error: 0.2467\n",
      "Epoch 130/150\n",
      "5839/5839 [==============================] - 0s 71us/step - loss: 0.7421 - mean_squared_error: 0.2140 - val_loss: 0.7708 - val_mean_squared_error: 0.2440\n",
      "Epoch 131/150\n",
      "5839/5839 [==============================] - 0s 65us/step - loss: 0.7418 - mean_squared_error: 0.2146 - val_loss: 0.7689 - val_mean_squared_error: 0.2448\n",
      "Epoch 132/150\n",
      "5839/5839 [==============================] - 0s 67us/step - loss: 0.7396 - mean_squared_error: 0.2132 - val_loss: 0.7697 - val_mean_squared_error: 0.2434\n",
      "Epoch 133/150\n",
      "5839/5839 [==============================] - 0s 67us/step - loss: 0.7419 - mean_squared_error: 0.2152 - val_loss: 0.7711 - val_mean_squared_error: 0.2454\n",
      "Epoch 134/150\n",
      "5839/5839 [==============================] - 0s 66us/step - loss: 0.7386 - mean_squared_error: 0.2134 - val_loss: 0.7684 - val_mean_squared_error: 0.2443\n",
      "Epoch 135/150\n",
      "5839/5839 [==============================] - 0s 69us/step - loss: 0.7397 - mean_squared_error: 0.2136 - val_loss: 0.7668 - val_mean_squared_error: 0.2430\n",
      "Epoch 136/150\n",
      "5839/5839 [==============================] - 0s 69us/step - loss: 0.7381 - mean_squared_error: 0.2139 - val_loss: 0.7691 - val_mean_squared_error: 0.2447\n",
      "Epoch 137/150\n",
      "5839/5839 [==============================] - 0s 79us/step - loss: 0.7386 - mean_squared_error: 0.2143 - val_loss: 0.7678 - val_mean_squared_error: 0.2436\n",
      "Epoch 138/150\n",
      "5839/5839 [==============================] - 1s 97us/step - loss: 0.7388 - mean_squared_error: 0.2138 - val_loss: 0.7666 - val_mean_squared_error: 0.2414\n",
      "Epoch 139/150\n",
      "5839/5839 [==============================] - 1s 101us/step - loss: 0.7383 - mean_squared_error: 0.2129 - val_loss: 0.7696 - val_mean_squared_error: 0.2443\n",
      "Epoch 140/150\n",
      "5839/5839 [==============================] - 0s 83us/step - loss: 0.7414 - mean_squared_error: 0.2137 - val_loss: 0.7704 - val_mean_squared_error: 0.2427\n",
      "Epoch 141/150\n",
      "5839/5839 [==============================] - 0s 83us/step - loss: 0.7397 - mean_squared_error: 0.2131 - val_loss: 0.7693 - val_mean_squared_error: 0.2450\n",
      "Epoch 142/150\n",
      "5839/5839 [==============================] - 0s 82us/step - loss: 0.7397 - mean_squared_error: 0.2139 - val_loss: 0.7692 - val_mean_squared_error: 0.2421\n",
      "Epoch 143/150\n",
      "5839/5839 [==============================] - 0s 76us/step - loss: 0.7401 - mean_squared_error: 0.2134 - val_loss: 0.7660 - val_mean_squared_error: 0.2413\n",
      "Epoch 144/150\n",
      "5839/5839 [==============================] - 0s 73us/step - loss: 0.7387 - mean_squared_error: 0.2133 - val_loss: 0.7772 - val_mean_squared_error: 0.2481\n",
      "Epoch 145/150\n",
      "5839/5839 [==============================] - 0s 75us/step - loss: 0.7404 - mean_squared_error: 0.2146 - val_loss: 0.7697 - val_mean_squared_error: 0.2468\n",
      "Epoch 146/150\n",
      "5839/5839 [==============================] - 0s 79us/step - loss: 0.7368 - mean_squared_error: 0.2138 - val_loss: 0.7629 - val_mean_squared_error: 0.2415\n",
      "Epoch 147/150\n",
      "5839/5839 [==============================] - 0s 74us/step - loss: 0.7376 - mean_squared_error: 0.2138 - val_loss: 0.7666 - val_mean_squared_error: 0.2405\n",
      "Epoch 148/150\n",
      "5839/5839 [==============================] - 1s 94us/step - loss: 0.7360 - mean_squared_error: 0.2136 - val_loss: 0.7697 - val_mean_squared_error: 0.2453\n",
      "Epoch 149/150\n",
      "5839/5839 [==============================] - 1s 119us/step - loss: 0.7363 - mean_squared_error: 0.2133 - val_loss: 0.7676 - val_mean_squared_error: 0.2424\n",
      "Epoch 150/150\n",
      "5839/5839 [==============================] - 1s 95us/step - loss: 0.7381 - mean_squared_error: 0.2139 - val_loss: 0.7623 - val_mean_squared_error: 0.2441\n",
      "Training MSE: 0.2129\n",
      "Validation MSE: 0.1812\n",
      "\n",
      "Training r2: 0.6049\n",
      "Validation r2: 0.6376\n"
     ]
    }
   ],
   "source": [
    "nn4 = models.Sequential()\n",
    "nn4.add(layers.Dense(128, input_shape=(X_train.shape[1],), kernel_regularizer=regularizers.l1(0.02), activation='relu'))\n",
    "nn4.add(layers.Dense(256, kernel_regularizer=regularizers.l1(0.02), activation='relu'))\n",
    "nn4.add(layers.Dense(512, kernel_regularizer=regularizers.l1(0.02), activation='relu'))\n",
    "nn4.add(layers.Dense(1, activation='relu'))\n",
    "\n",
    "# Compiling the model\n",
    "nn4.compile(loss='mean_squared_error',\n",
    "            optimizer='adam',\n",
    "            metrics=['mean_squared_error'])\n",
    "\n",
    "nn4_history = nn4.fit(X_train,\n",
    "                  y_train,\n",
    "                  epochs=150,\n",
    "                  batch_size=256,\n",
    "                  validation_split = 0.1)\n",
    "\n",
    "nn_model_evaluation(nn4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
